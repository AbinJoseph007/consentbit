/*
 * ATTENTION: The "eval" devtool has been used (maybe by default in mode: "development").
 * This devtool is neither made for production nor for readable output files.
 * It uses "eval()" calls to create a separate source file in the browser devtools.
 * If you are trying to read the output file, select a different devtool (https://webpack.js.org/configuration/devtool/)
 * or disable the default devtool with "devtool: false".
 * If you are looking for production-ready output files, see mode: "production" (https://webpack.js.org/configuration/mode/).
 */
(self["webpackChunkconsentbit"] = self["webpackChunkconsentbit"] || []).push([["vendors-node_modules_tar-fs_index_js"],{

/***/ "./node_modules/b4a/browser.js":
/*!*************************************!*\
  !*** ./node_modules/b4a/browser.js ***!
  \*************************************/
/***/ ((module, exports, __webpack_require__) => {

eval("const ascii = __webpack_require__(/*! ./lib/ascii */ \"./node_modules/b4a/lib/ascii.js\")\nconst base64 = __webpack_require__(/*! ./lib/base64 */ \"./node_modules/b4a/lib/base64.js\")\nconst hex = __webpack_require__(/*! ./lib/hex */ \"./node_modules/b4a/lib/hex.js\")\nconst utf8 = __webpack_require__(/*! ./lib/utf8 */ \"./node_modules/b4a/lib/utf8.js\")\nconst utf16le = __webpack_require__(/*! ./lib/utf16le */ \"./node_modules/b4a/lib/utf16le.js\")\n\nconst LE = new Uint8Array(Uint16Array.of(0xff).buffer)[0] === 0xff\n\nfunction codecFor (encoding) {\n  switch (encoding) {\n    case 'ascii':\n      return ascii\n    case 'base64':\n      return base64\n    case 'hex':\n      return hex\n    case 'utf8':\n    case 'utf-8':\n    case undefined:\n    case null:\n      return utf8\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return utf16le\n    default:\n      throw new Error(`Unknown encoding: ${encoding}`)\n  }\n}\n\nfunction isBuffer (value) {\n  return value instanceof Uint8Array\n}\n\nfunction isEncoding (encoding) {\n  try {\n    codecFor(encoding)\n    return true\n  } catch {\n    return false\n  }\n}\n\nfunction alloc (size, fill, encoding) {\n  const buffer = new Uint8Array(size)\n  if (fill !== undefined) exports.fill(buffer, fill, 0, buffer.byteLength, encoding)\n  return buffer\n}\n\nfunction allocUnsafe (size) {\n  return new Uint8Array(size)\n}\n\nfunction allocUnsafeSlow (size) {\n  return new Uint8Array(size)\n}\n\nfunction byteLength (string, encoding) {\n  return codecFor(encoding).byteLength(string)\n}\n\nfunction compare (a, b) {\n  if (a === b) return 0\n\n  const len = Math.min(a.byteLength, b.byteLength)\n\n  a = new DataView(a.buffer, a.byteOffset, a.byteLength)\n  b = new DataView(b.buffer, b.byteOffset, b.byteLength)\n\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    const x = a.getUint32(i, LE)\n    const y = b.getUint32(i, LE)\n    if (x !== y) break\n  }\n\n  for (; i < len; i++) {\n    const x = a.getUint8(i)\n    const y = b.getUint8(i)\n    if (x < y) return -1\n    if (x > y) return 1\n  }\n\n  return a.byteLength > b.byteLength ? 1 : a.byteLength < b.byteLength ? -1 : 0\n}\n\nfunction concat (buffers, totalLength) {\n  if (totalLength === undefined) {\n    totalLength = buffers.reduce((len, buffer) => len + buffer.byteLength, 0)\n  }\n\n  const result = new Uint8Array(totalLength)\n\n  let offset = 0\n  for (const buffer of buffers) {\n    if (offset + buffer.byteLength > result.byteLength) {\n      const sub = buffer.subarray(0, result.byteLength - offset)\n      result.set(sub, offset)\n      return result\n    }\n    result.set(buffer, offset)\n    offset += buffer.byteLength\n  }\n\n  return result\n}\n\nfunction copy (source, target, targetStart = 0, start = 0, end = source.byteLength) {\n  if (end > 0 && end < start) return 0\n  if (end === start) return 0\n  if (source.byteLength === 0 || target.byteLength === 0) return 0\n\n  if (targetStart < 0) throw new RangeError('targetStart is out of range')\n  if (start < 0 || start >= source.byteLength) throw new RangeError('sourceStart is out of range')\n  if (end < 0) throw new RangeError('sourceEnd is out of range')\n\n  if (targetStart >= target.byteLength) targetStart = target.byteLength\n  if (end > source.byteLength) end = source.byteLength\n  if (target.byteLength - targetStart < end - start) {\n    end = target.length - targetStart + start\n  }\n\n  const len = end - start\n\n  if (source === target) {\n    target.copyWithin(targetStart, start, end)\n  } else {\n    target.set(source.subarray(start, end), targetStart)\n  }\n\n  return len\n}\n\nfunction equals (a, b) {\n  if (a === b) return true\n  if (a.byteLength !== b.byteLength) return false\n\n  const len = a.byteLength\n\n  a = new DataView(a.buffer, a.byteOffset, a.byteLength)\n  b = new DataView(b.buffer, b.byteOffset, b.byteLength)\n\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    if (a.getUint32(i, LE) !== b.getUint32(i, LE)) return false\n  }\n\n  for (; i < len; i++) {\n    if (a.getUint8(i) !== b.getUint8(i)) return false\n  }\n\n  return true\n}\n\nfunction fill (buffer, value, offset, end, encoding) {\n  if (typeof value === 'string') {\n    // fill(buffer, string, encoding)\n    if (typeof offset === 'string') {\n      encoding = offset\n      offset = 0\n      end = buffer.byteLength\n\n    // fill(buffer, string, offset, encoding)\n    } else if (typeof end === 'string') {\n      encoding = end\n      end = buffer.byteLength\n    }\n  } else if (typeof value === 'number') {\n    value = value & 0xff\n  } else if (typeof value === 'boolean') {\n    value = +value\n  }\n\n  if (offset < 0 || buffer.byteLength < offset || buffer.byteLength < end) {\n    throw new RangeError('Out of range index')\n  }\n\n  if (offset === undefined) offset = 0\n  if (end === undefined) end = buffer.byteLength\n\n  if (end <= offset) return buffer\n\n  if (!value) value = 0\n\n  if (typeof value === 'number') {\n    for (let i = offset; i < end; ++i) {\n      buffer[i] = value\n    }\n  } else {\n    value = isBuffer(value) ? value : from(value, encoding)\n\n    const len = value.byteLength\n\n    for (let i = 0; i < end - offset; ++i) {\n      buffer[i + offset] = value[i % len]\n    }\n  }\n\n  return buffer\n}\n\nfunction from (value, encodingOrOffset, length) {\n  // from(string, encoding)\n  if (typeof value === 'string') return fromString(value, encodingOrOffset)\n\n  // from(array)\n  if (Array.isArray(value)) return fromArray(value)\n\n  // from(buffer)\n  if (ArrayBuffer.isView(value)) return fromBuffer(value)\n\n  // from(arrayBuffer[, byteOffset[, length]])\n  return fromArrayBuffer(value, encodingOrOffset, length)\n}\n\nfunction fromString (string, encoding) {\n  const codec = codecFor(encoding)\n  const buffer = new Uint8Array(codec.byteLength(string))\n  codec.write(buffer, string, 0, buffer.byteLength)\n  return buffer\n}\n\nfunction fromArray (array) {\n  const buffer = new Uint8Array(array.length)\n  buffer.set(array)\n  return buffer\n}\n\nfunction fromBuffer (buffer) {\n  const copy = new Uint8Array(buffer.byteLength)\n  copy.set(buffer)\n  return copy\n}\n\nfunction fromArrayBuffer (arrayBuffer, byteOffset, length) {\n  return new Uint8Array(arrayBuffer, byteOffset, length)\n}\n\nfunction includes (buffer, value, byteOffset, encoding) {\n  return indexOf(buffer, value, byteOffset, encoding) !== -1\n}\n\nfunction bidirectionalIndexOf (buffer, value, byteOffset, encoding, first) {\n  if (buffer.byteLength === 0) return -1\n\n  if (typeof byteOffset === 'string') {\n    encoding = byteOffset\n    byteOffset = 0\n  } else if (byteOffset === undefined) {\n    byteOffset = first ? 0 : (buffer.length - 1)\n  } else if (byteOffset < 0) {\n    byteOffset += buffer.byteLength\n  }\n\n  if (byteOffset >= buffer.byteLength) {\n    if (first) return -1\n    else byteOffset = buffer.byteLength - 1\n  } else if (byteOffset < 0) {\n    if (first) byteOffset = 0\n    else return -1\n  }\n\n  if (typeof value === 'string') {\n    value = from(value, encoding)\n  } else if (typeof value === 'number') {\n    value = value & 0xff\n\n    if (first) {\n      return buffer.indexOf(value, byteOffset)\n    } else {\n      return buffer.lastIndexOf(value, byteOffset)\n    }\n  }\n\n  if (value.byteLength === 0) return -1\n\n  if (first) {\n    let foundIndex = -1\n\n    for (let i = byteOffset; i < buffer.byteLength; i++) {\n      if (buffer[i] === value[foundIndex === -1 ? 0 : i - foundIndex]) {\n        if (foundIndex === -1) foundIndex = i\n        if (i - foundIndex + 1 === value.byteLength) return foundIndex\n      } else {\n        if (foundIndex !== -1) i -= i - foundIndex\n        foundIndex = -1\n      }\n    }\n  } else {\n    if (byteOffset + value.byteLength > buffer.byteLength) {\n      byteOffset = buffer.byteLength - value.byteLength\n    }\n\n    for (let i = byteOffset; i >= 0; i--) {\n      let found = true\n\n      for (let j = 0; j < value.byteLength; j++) {\n        if (buffer[i + j] !== value[j]) {\n          found = false\n          break\n        }\n      }\n\n      if (found) return i\n    }\n  }\n\n  return -1\n}\n\nfunction indexOf (buffer, value, byteOffset, encoding) {\n  return bidirectionalIndexOf(buffer, value, byteOffset, encoding, true /* first */)\n}\n\nfunction lastIndexOf (buffer, value, byteOffset, encoding) {\n  return bidirectionalIndexOf(buffer, value, byteOffset, encoding, false /* last */)\n}\n\nfunction swap (buffer, n, m) {\n  const i = buffer[n]\n  buffer[n] = buffer[m]\n  buffer[m] = i\n}\n\nfunction swap16 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 2 !== 0) throw new RangeError('Buffer size must be a multiple of 16-bits')\n\n  for (let i = 0; i < len; i += 2) swap(buffer, i, i + 1)\n\n  return buffer\n}\n\nfunction swap32 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 4 !== 0) throw new RangeError('Buffer size must be a multiple of 32-bits')\n\n  for (let i = 0; i < len; i += 4) {\n    swap(buffer, i, i + 3)\n    swap(buffer, i + 1, i + 2)\n  }\n\n  return buffer\n}\n\nfunction swap64 (buffer) {\n  const len = buffer.byteLength\n\n  if (len % 8 !== 0) throw new RangeError('Buffer size must be a multiple of 64-bits')\n\n  for (let i = 0; i < len; i += 8) {\n    swap(buffer, i, i + 7)\n    swap(buffer, i + 1, i + 6)\n    swap(buffer, i + 2, i + 5)\n    swap(buffer, i + 3, i + 4)\n  }\n\n  return buffer\n}\n\nfunction toBuffer (buffer) {\n  return buffer\n}\n\nfunction toString (buffer, encoding, start = 0, end = buffer.byteLength) {\n  const len = buffer.byteLength\n\n  if (start >= len) return ''\n  if (end <= start) return ''\n  if (start < 0) start = 0\n  if (end > len) end = len\n\n  if (start !== 0 || end < len) buffer = buffer.subarray(start, end)\n\n  return codecFor(encoding).toString(buffer)\n}\n\nfunction write (buffer, string, offset, length, encoding) {\n  // write(buffer, string)\n  if (offset === undefined) {\n    encoding = 'utf8'\n\n  // write(buffer, string, encoding)\n  } else if (length === undefined && typeof offset === 'string') {\n    encoding = offset\n    offset = undefined\n\n  // write(buffer, string, offset, encoding)\n  } else if (encoding === undefined && typeof length === 'string') {\n    encoding = length\n    length = undefined\n  }\n\n  return codecFor(encoding).write(buffer, string, offset, length)\n}\n\nfunction writeDoubleLE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat64(offset, value, true)\n\n  return offset + 8\n}\n\nfunction writeFloatLE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction writeUInt32LE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setUint32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction writeInt32LE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setInt32(offset, value, true)\n\n  return offset + 4\n}\n\nfunction readDoubleLE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat64(offset, true)\n}\n\nfunction readFloatLE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat32(offset, true)\n}\n\nfunction readUInt32LE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getUint32(offset, true)\n}\n\nfunction readInt32LE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getInt32(offset, true)\n}\n\nfunction writeDoubleBE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat64(offset, value, false)\n\n  return offset + 8\n}\n\nfunction writeFloatBE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setFloat32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction writeUInt32BE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setUint32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction writeInt32BE (buffer, value, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n  view.setInt32(offset, value, false)\n\n  return offset + 4\n}\n\nfunction readDoubleBE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat64(offset, false)\n}\n\nfunction readFloatBE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getFloat32(offset, false)\n}\n\nfunction readUInt32BE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getUint32(offset, false)\n}\n\nfunction readInt32BE (buffer, offset) {\n  if (offset === undefined) offset = 0\n\n  const view = new DataView(buffer.buffer, buffer.byteOffset, buffer.byteLength)\n\n  return view.getInt32(offset, false)\n}\n\nmodule.exports = exports = {\n  isBuffer,\n  isEncoding,\n  alloc,\n  allocUnsafe,\n  allocUnsafeSlow,\n  byteLength,\n  compare,\n  concat,\n  copy,\n  equals,\n  fill,\n  from,\n  includes,\n  indexOf,\n  lastIndexOf,\n  swap16,\n  swap32,\n  swap64,\n  toBuffer,\n  toString,\n  write,\n  writeDoubleLE,\n  writeFloatLE,\n  writeUInt32LE,\n  writeInt32LE,\n  readDoubleLE,\n  readFloatLE,\n  readUInt32LE,\n  readInt32LE,\n  writeDoubleBE,\n  writeFloatBE,\n  writeUInt32BE,\n  writeInt32BE,\n  readDoubleBE,\n  readFloatBE,\n  readUInt32BE,\n  readInt32BE\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/browser.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/ascii.js":
/*!***************************************!*\
  !*** ./node_modules/b4a/lib/ascii.js ***!
  \***************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len; i++) {\n    result += String.fromCharCode(buffer[i])\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0; i < len; i++) {\n    buffer[offset + i] = string.charCodeAt(i)\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/lib/ascii.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/base64.js":
/*!****************************************!*\
  !*** ./node_modules/b4a/lib/base64.js ***!
  \****************************************/
/***/ ((module) => {

eval("const alphabet = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz0123456789+/'\n\nconst codes = new Uint8Array(256)\n\nfor (let i = 0; i < alphabet.length; i++) {\n  codes[alphabet.charCodeAt(i)] = i\n}\n\ncodes[/* - */ 0x2d] = 62\ncodes[/* _ */ 0x5f] = 63\n\nfunction byteLength (string) {\n  let len = string.length\n\n  if (string.charCodeAt(len - 1) === 0x3d) len--\n  if (len > 1 && string.charCodeAt(len - 1) === 0x3d) len--\n\n  return (len * 3) >>> 2\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len; i += 3) {\n    result += (\n      alphabet[buffer[i] >> 2] +\n      alphabet[((buffer[i] & 3) << 4) | (buffer[i + 1] >> 4)] +\n      alphabet[((buffer[i + 1] & 15) << 2) | (buffer[i + 2] >> 6)] +\n      alphabet[buffer[i + 2] & 63]\n    )\n  }\n\n  if (len % 3 === 2) {\n    result = result.substring(0, result.length - 1) + '='\n  } else if (len % 3 === 1) {\n    result = result.substring(0, result.length - 2) + '=='\n  }\n\n  return result\n};\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0, j = 0; j < len; i += 4) {\n    const a = codes[string.charCodeAt(i)]\n    const b = codes[string.charCodeAt(i + 1)]\n    const c = codes[string.charCodeAt(i + 2)]\n    const d = codes[string.charCodeAt(i + 3)]\n\n    buffer[j++] = (a << 2) | (b >> 4)\n    buffer[j++] = ((b & 15) << 4) | (c >> 2)\n    buffer[j++] = ((c & 3) << 6) | (d & 63)\n  }\n\n  return len\n};\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/lib/base64.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/hex.js":
/*!*************************************!*\
  !*** ./node_modules/b4a/lib/hex.js ***!
  \*************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length >>> 1\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  buffer = new DataView(buffer.buffer, buffer.byteOffset, len)\n\n  let result = ''\n  let i = 0\n\n  for (let n = len - (len % 4); i < n; i += 4) {\n    result += buffer.getUint32(i).toString(16).padStart(8, '0')\n  }\n\n  for (; i < len; i++) {\n    result += buffer.getUint8(i).toString(16).padStart(2, '0')\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  for (let i = 0; i < len; i++) {\n    const a = hexValue(string.charCodeAt(i * 2))\n    const b = hexValue(string.charCodeAt(i * 2 + 1))\n\n    if (a === undefined || b === undefined) {\n      return buffer.subarray(0, i)\n    }\n\n    buffer[offset + i] = (a << 4) | b\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\nfunction hexValue (char) {\n  if (char >= 0x30 && char <= 0x39) return char - 0x30\n  if (char >= 0x41 && char <= 0x46) return char - 0x41 + 10\n  if (char >= 0x61 && char <= 0x66) return char - 0x61 + 10\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/lib/hex.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/utf16le.js":
/*!*****************************************!*\
  !*** ./node_modules/b4a/lib/utf16le.js ***!
  \*****************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  return string.length * 2\n}\n\nfunction toString (buffer) {\n  const len = buffer.byteLength\n\n  let result = ''\n\n  for (let i = 0; i < len - 1; i += 2) {\n    result += String.fromCharCode(buffer[i] + (buffer[i + 1] * 256))\n  }\n\n  return result\n}\n\nfunction write (buffer, string, offset = 0, length = byteLength(string)) {\n  const len = Math.min(length, buffer.byteLength - offset)\n\n  let units = len\n\n  for (let i = 0; i < string.length; ++i) {\n    if ((units -= 2) < 0) break\n\n    const c = string.charCodeAt(i)\n    const hi = c >> 8\n    const lo = c % 256\n\n    buffer[offset + i * 2] = lo\n    buffer[offset + i * 2 + 1] = hi\n  }\n\n  return len\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/lib/utf16le.js?");

/***/ }),

/***/ "./node_modules/b4a/lib/utf8.js":
/*!**************************************!*\
  !*** ./node_modules/b4a/lib/utf8.js ***!
  \**************************************/
/***/ ((module) => {

eval("function byteLength (string) {\n  let length = 0\n\n  for (let i = 0, n = string.length; i < n; i++) {\n    const code = string.charCodeAt(i)\n\n    if (code >= 0xd800 && code <= 0xdbff && i + 1 < n) {\n      const code = string.charCodeAt(i + 1)\n\n      if (code >= 0xdc00 && code <= 0xdfff) {\n        length += 4\n        i++\n        continue\n      }\n    }\n\n    if (code <= 0x7f) length += 1\n    else if (code <= 0x7ff) length += 2\n    else length += 3\n  }\n\n  return length\n}\n\nlet toString\n\nif (typeof TextDecoder !== 'undefined') {\n  const decoder = new TextDecoder()\n\n  toString = function toString (buffer) {\n    return decoder.decode(buffer)\n  }\n} else {\n  toString = function toString (buffer) {\n    const len = buffer.byteLength\n\n    let output = ''\n    let i = 0\n\n    while (i < len) {\n      let byte = buffer[i]\n\n      if (byte <= 0x7f) {\n        output += String.fromCharCode(byte)\n        i++\n        continue\n      }\n\n      let bytesNeeded = 0\n      let codePoint = 0\n\n      if (byte <= 0xdf) {\n        bytesNeeded = 1\n        codePoint = byte & 0x1f\n      } else if (byte <= 0xef) {\n        bytesNeeded = 2\n        codePoint = byte & 0x0f\n      } else if (byte <= 0xf4) {\n        bytesNeeded = 3\n        codePoint = byte & 0x07\n      }\n\n      if (len - i - bytesNeeded > 0) {\n        let k = 0\n\n        while (k < bytesNeeded) {\n          byte = buffer[i + k + 1]\n          codePoint = (codePoint << 6) | (byte & 0x3f)\n          k += 1\n        }\n      } else {\n        codePoint = 0xfffd\n        bytesNeeded = len - i\n      }\n\n      output += String.fromCodePoint(codePoint)\n      i += bytesNeeded + 1\n    }\n\n    return output\n  }\n}\n\nlet write\n\nif (typeof TextEncoder !== 'undefined') {\n  const encoder = new TextEncoder()\n\n  write = function write (buffer, string, offset = 0, length = byteLength(string)) {\n    const len = Math.min(length, buffer.byteLength - offset)\n    encoder.encodeInto(string, buffer.subarray(offset, offset + len))\n    return len\n  }\n} else {\n  write = function write (buffer, string, offset = 0, length = byteLength(string)) {\n    const len = Math.min(length, buffer.byteLength - offset)\n\n    buffer = buffer.subarray(offset, offset + len)\n\n    let i = 0\n    let j = 0\n\n    while (i < string.length) {\n      const code = string.codePointAt(i)\n\n      if (code <= 0x7f) {\n        buffer[j++] = code\n        i++\n        continue\n      }\n\n      let count = 0\n      let bits = 0\n\n      if (code <= 0x7ff) {\n        count = 6\n        bits = 0xc0\n      } else if (code <= 0xffff) {\n        count = 12\n        bits = 0xe0\n      } else if (code <= 0x1fffff) {\n        count = 18\n        bits = 0xf0\n      }\n\n      buffer[j++] = bits | (code >> count)\n      count -= 6\n\n      while (count >= 0) {\n        buffer[j++] = 0x80 | ((code >> count) & 0x3f)\n        count -= 6\n      }\n\n      i += code >= 0x10000 ? 2 : 1\n    }\n\n    return len\n  }\n}\n\nmodule.exports = {\n  byteLength,\n  toString,\n  write\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/b4a/lib/utf8.js?");

/***/ }),

/***/ "./node_modules/end-of-stream/index.js":
/*!*********************************************!*\
  !*** ./node_modules/end-of-stream/index.js ***!
  \*********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\");\n\nvar noop = function() {};\n\nvar isRequest = function(stream) {\n\treturn stream.setHeader && typeof stream.abort === 'function';\n};\n\nvar isChildProcess = function(stream) {\n\treturn stream.stdio && Array.isArray(stream.stdio) && stream.stdio.length === 3\n};\n\nvar eos = function(stream, opts, callback) {\n\tif (typeof opts === 'function') return eos(stream, null, opts);\n\tif (!opts) opts = {};\n\n\tcallback = once(callback || noop);\n\n\tvar ws = stream._writableState;\n\tvar rs = stream._readableState;\n\tvar readable = opts.readable || (opts.readable !== false && stream.readable);\n\tvar writable = opts.writable || (opts.writable !== false && stream.writable);\n\tvar cancelled = false;\n\n\tvar onlegacyfinish = function() {\n\t\tif (!stream.writable) onfinish();\n\t};\n\n\tvar onfinish = function() {\n\t\twritable = false;\n\t\tif (!readable) callback.call(stream);\n\t};\n\n\tvar onend = function() {\n\t\treadable = false;\n\t\tif (!writable) callback.call(stream);\n\t};\n\n\tvar onexit = function(exitCode) {\n\t\tcallback.call(stream, exitCode ? new Error('exited with error code: ' + exitCode) : null);\n\t};\n\n\tvar onerror = function(err) {\n\t\tcallback.call(stream, err);\n\t};\n\n\tvar onclose = function() {\n\t\tprocess.nextTick(onclosenexttick);\n\t};\n\n\tvar onclosenexttick = function() {\n\t\tif (cancelled) return;\n\t\tif (readable && !(rs && (rs.ended && !rs.destroyed))) return callback.call(stream, new Error('premature close'));\n\t\tif (writable && !(ws && (ws.ended && !ws.destroyed))) return callback.call(stream, new Error('premature close'));\n\t};\n\n\tvar onrequest = function() {\n\t\tstream.req.on('finish', onfinish);\n\t};\n\n\tif (isRequest(stream)) {\n\t\tstream.on('complete', onfinish);\n\t\tstream.on('abort', onclose);\n\t\tif (stream.req) onrequest();\n\t\telse stream.on('request', onrequest);\n\t} else if (writable && !ws) { // legacy streams\n\t\tstream.on('end', onlegacyfinish);\n\t\tstream.on('close', onlegacyfinish);\n\t}\n\n\tif (isChildProcess(stream)) stream.on('exit', onexit);\n\n\tstream.on('end', onend);\n\tstream.on('finish', onfinish);\n\tif (opts.error !== false) stream.on('error', onerror);\n\tstream.on('close', onclose);\n\n\treturn function() {\n\t\tcancelled = true;\n\t\tstream.removeListener('complete', onfinish);\n\t\tstream.removeListener('abort', onclose);\n\t\tstream.removeListener('request', onrequest);\n\t\tif (stream.req) stream.req.removeListener('finish', onfinish);\n\t\tstream.removeListener('end', onlegacyfinish);\n\t\tstream.removeListener('close', onlegacyfinish);\n\t\tstream.removeListener('finish', onfinish);\n\t\tstream.removeListener('exit', onexit);\n\t\tstream.removeListener('end', onend);\n\t\tstream.removeListener('error', onerror);\n\t\tstream.removeListener('close', onclose);\n\t};\n};\n\nmodule.exports = eos;\n\n\n//# sourceURL=webpack://consentbit/./node_modules/end-of-stream/index.js?");

/***/ }),

/***/ "./node_modules/fast-fifo/fixed-size.js":
/*!**********************************************!*\
  !*** ./node_modules/fast-fifo/fixed-size.js ***!
  \**********************************************/
/***/ ((module) => {

eval("module.exports = class FixedFIFO {\n  constructor (hwm) {\n    if (!(hwm > 0) || ((hwm - 1) & hwm) !== 0) throw new Error('Max size for a FixedFIFO should be a power of two')\n    this.buffer = new Array(hwm)\n    this.mask = hwm - 1\n    this.top = 0\n    this.btm = 0\n    this.next = null\n  }\n\n  clear () {\n    this.top = this.btm = 0\n    this.next = null\n    this.buffer.fill(undefined)\n  }\n\n  push (data) {\n    if (this.buffer[this.top] !== undefined) return false\n    this.buffer[this.top] = data\n    this.top = (this.top + 1) & this.mask\n    return true\n  }\n\n  shift () {\n    const last = this.buffer[this.btm]\n    if (last === undefined) return undefined\n    this.buffer[this.btm] = undefined\n    this.btm = (this.btm + 1) & this.mask\n    return last\n  }\n\n  peek () {\n    return this.buffer[this.btm]\n  }\n\n  isEmpty () {\n    return this.buffer[this.btm] === undefined\n  }\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/fast-fifo/fixed-size.js?");

/***/ }),

/***/ "./node_modules/fast-fifo/index.js":
/*!*****************************************!*\
  !*** ./node_modules/fast-fifo/index.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const FixedFIFO = __webpack_require__(/*! ./fixed-size */ \"./node_modules/fast-fifo/fixed-size.js\")\n\nmodule.exports = class FastFIFO {\n  constructor (hwm) {\n    this.hwm = hwm || 16\n    this.head = new FixedFIFO(this.hwm)\n    this.tail = this.head\n    this.length = 0\n  }\n\n  clear () {\n    this.head = this.tail\n    this.head.clear()\n    this.length = 0\n  }\n\n  push (val) {\n    this.length++\n    if (!this.head.push(val)) {\n      const prev = this.head\n      this.head = prev.next = new FixedFIFO(2 * this.head.buffer.length)\n      this.head.push(val)\n    }\n  }\n\n  shift () {\n    if (this.length !== 0) this.length--\n    const val = this.tail.shift()\n    if (val === undefined && this.tail.next) {\n      const next = this.tail.next\n      this.tail.next = null\n      this.tail = next\n      return this.tail.shift()\n    }\n\n    return val\n  }\n\n  peek () {\n    const val = this.tail.peek()\n    if (val === undefined && this.tail.next) return this.tail.next.peek()\n    return val\n  }\n\n  isEmpty () {\n    return this.length === 0\n  }\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/fast-fifo/index.js?");

/***/ }),

/***/ "./node_modules/once/once.js":
/*!***********************************!*\
  !*** ./node_modules/once/once.js ***!
  \***********************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var wrappy = __webpack_require__(/*! wrappy */ \"./node_modules/wrappy/wrappy.js\")\nmodule.exports = wrappy(once)\nmodule.exports.strict = wrappy(onceStrict)\n\nonce.proto = once(function () {\n  Object.defineProperty(Function.prototype, 'once', {\n    value: function () {\n      return once(this)\n    },\n    configurable: true\n  })\n\n  Object.defineProperty(Function.prototype, 'onceStrict', {\n    value: function () {\n      return onceStrict(this)\n    },\n    configurable: true\n  })\n})\n\nfunction once (fn) {\n  var f = function () {\n    if (f.called) return f.value\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  f.called = false\n  return f\n}\n\nfunction onceStrict (fn) {\n  var f = function () {\n    if (f.called)\n      throw new Error(f.onceError)\n    f.called = true\n    return f.value = fn.apply(this, arguments)\n  }\n  var name = fn.name || 'Function wrapped with `once`'\n  f.onceError = name + \" shouldn't be called more than once\"\n  f.called = false\n  return f\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/once/once.js?");

/***/ }),

/***/ "./node_modules/pump/index.js":
/*!************************************!*\
  !*** ./node_modules/pump/index.js ***!
  \************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("var once = __webpack_require__(/*! once */ \"./node_modules/once/once.js\")\nvar eos = __webpack_require__(/*! end-of-stream */ \"./node_modules/end-of-stream/index.js\")\nvar fs\n\ntry {\n  fs = __webpack_require__(/*! fs */ \"?7874\") // we only need fs to get the ReadStream and WriteStream prototypes\n} catch (e) {}\n\nvar noop = function () {}\nvar ancient = /^v?\\.0/.test(process.version)\n\nvar isFn = function (fn) {\n  return typeof fn === 'function'\n}\n\nvar isFS = function (stream) {\n  if (!ancient) return false // newer node version do not need to care about fs is a special way\n  if (!fs) return false // browser\n  return (stream instanceof (fs.ReadStream || noop) || stream instanceof (fs.WriteStream || noop)) && isFn(stream.close)\n}\n\nvar isRequest = function (stream) {\n  return stream.setHeader && isFn(stream.abort)\n}\n\nvar destroyer = function (stream, reading, writing, callback) {\n  callback = once(callback)\n\n  var closed = false\n  stream.on('close', function () {\n    closed = true\n  })\n\n  eos(stream, {readable: reading, writable: writing}, function (err) {\n    if (err) return callback(err)\n    closed = true\n    callback()\n  })\n\n  var destroyed = false\n  return function (err) {\n    if (closed) return\n    if (destroyed) return\n    destroyed = true\n\n    if (isFS(stream)) return stream.close(noop) // use close for fs streams to avoid fd leaks\n    if (isRequest(stream)) return stream.abort() // request.destroy just do .end - .abort is what we want\n\n    if (isFn(stream.destroy)) return stream.destroy()\n\n    callback(err || new Error('stream was destroyed'))\n  }\n}\n\nvar call = function (fn) {\n  fn()\n}\n\nvar pipe = function (from, to) {\n  return from.pipe(to)\n}\n\nvar pump = function () {\n  var streams = Array.prototype.slice.call(arguments)\n  var callback = isFn(streams[streams.length - 1] || noop) && streams.pop() || noop\n\n  if (Array.isArray(streams[0])) streams = streams[0]\n  if (streams.length < 2) throw new Error('pump requires two streams per minimum')\n\n  var error\n  var destroys = streams.map(function (stream, i) {\n    var reading = i < streams.length - 1\n    var writing = i > 0\n    return destroyer(stream, reading, writing, function (err) {\n      if (!error) error = err\n      if (err) destroys.forEach(call)\n      if (reading) return\n      destroys.forEach(call)\n      callback(error)\n    })\n  })\n\n  return streams.reduce(pipe)\n}\n\nmodule.exports = pump\n\n\n//# sourceURL=webpack://consentbit/./node_modules/pump/index.js?");

/***/ }),

/***/ "./node_modules/streamx/index.js":
/*!***************************************!*\
  !*** ./node_modules/streamx/index.js ***!
  \***************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { EventEmitter } = __webpack_require__(/*! events */ \"./node_modules/events/events.js\")\nconst STREAM_DESTROYED = new Error('Stream was destroyed')\nconst PREMATURE_CLOSE = new Error('Premature close')\n\nconst FIFO = __webpack_require__(/*! fast-fifo */ \"./node_modules/fast-fifo/index.js\")\nconst TextDecoder = __webpack_require__(/*! text-decoder */ \"./node_modules/text-decoder/index.js\")\n\n/* eslint-disable no-multi-spaces */\n\n// 29 bits used total (4 from shared, 14 from read, and 11 from write)\nconst MAX = ((1 << 29) - 1)\n\n// Shared state\nconst OPENING       = 0b0001\nconst PREDESTROYING = 0b0010\nconst DESTROYING    = 0b0100\nconst DESTROYED     = 0b1000\n\nconst NOT_OPENING = MAX ^ OPENING\nconst NOT_PREDESTROYING = MAX ^ PREDESTROYING\n\n// Read state (4 bit offset from shared state)\nconst READ_ACTIVE           = 0b00000000000001 << 4\nconst READ_UPDATING         = 0b00000000000010 << 4\nconst READ_PRIMARY          = 0b00000000000100 << 4\nconst READ_QUEUED           = 0b00000000001000 << 4\nconst READ_RESUMED          = 0b00000000010000 << 4\nconst READ_PIPE_DRAINED     = 0b00000000100000 << 4\nconst READ_ENDING           = 0b00000001000000 << 4\nconst READ_EMIT_DATA        = 0b00000010000000 << 4\nconst READ_EMIT_READABLE    = 0b00000100000000 << 4\nconst READ_EMITTED_READABLE = 0b00001000000000 << 4\nconst READ_DONE             = 0b00010000000000 << 4\nconst READ_NEXT_TICK        = 0b00100000000000 << 4\nconst READ_NEEDS_PUSH       = 0b01000000000000 << 4\nconst READ_READ_AHEAD       = 0b10000000000000 << 4\n\n// Combined read state\nconst READ_FLOWING = READ_RESUMED | READ_PIPE_DRAINED\nconst READ_ACTIVE_AND_NEEDS_PUSH = READ_ACTIVE | READ_NEEDS_PUSH\nconst READ_PRIMARY_AND_ACTIVE = READ_PRIMARY | READ_ACTIVE\nconst READ_EMIT_READABLE_AND_QUEUED = READ_EMIT_READABLE | READ_QUEUED\nconst READ_RESUMED_READ_AHEAD = READ_RESUMED | READ_READ_AHEAD\n\nconst READ_NOT_ACTIVE             = MAX ^ READ_ACTIVE\nconst READ_NON_PRIMARY            = MAX ^ READ_PRIMARY\nconst READ_NON_PRIMARY_AND_PUSHED = MAX ^ (READ_PRIMARY | READ_NEEDS_PUSH)\nconst READ_PUSHED                 = MAX ^ READ_NEEDS_PUSH\nconst READ_PAUSED                 = MAX ^ READ_RESUMED\nconst READ_NOT_QUEUED             = MAX ^ (READ_QUEUED | READ_EMITTED_READABLE)\nconst READ_NOT_ENDING             = MAX ^ READ_ENDING\nconst READ_PIPE_NOT_DRAINED       = MAX ^ READ_FLOWING\nconst READ_NOT_NEXT_TICK          = MAX ^ READ_NEXT_TICK\nconst READ_NOT_UPDATING           = MAX ^ READ_UPDATING\nconst READ_NO_READ_AHEAD          = MAX ^ READ_READ_AHEAD\nconst READ_PAUSED_NO_READ_AHEAD   = MAX ^ READ_RESUMED_READ_AHEAD\n\n// Write state (18 bit offset, 4 bit offset from shared state and 14 from read state)\nconst WRITE_ACTIVE     = 0b00000000001 << 18\nconst WRITE_UPDATING   = 0b00000000010 << 18\nconst WRITE_PRIMARY    = 0b00000000100 << 18\nconst WRITE_QUEUED     = 0b00000001000 << 18\nconst WRITE_UNDRAINED  = 0b00000010000 << 18\nconst WRITE_DONE       = 0b00000100000 << 18\nconst WRITE_EMIT_DRAIN = 0b00001000000 << 18\nconst WRITE_NEXT_TICK  = 0b00010000000 << 18\nconst WRITE_WRITING    = 0b00100000000 << 18\nconst WRITE_FINISHING  = 0b01000000000 << 18\nconst WRITE_CORKED     = 0b10000000000 << 18\n\nconst WRITE_NOT_ACTIVE    = MAX ^ (WRITE_ACTIVE | WRITE_WRITING)\nconst WRITE_NON_PRIMARY   = MAX ^ WRITE_PRIMARY\nconst WRITE_NOT_FINISHING = MAX ^ (WRITE_ACTIVE | WRITE_FINISHING)\nconst WRITE_DRAINED       = MAX ^ WRITE_UNDRAINED\nconst WRITE_NOT_QUEUED    = MAX ^ WRITE_QUEUED\nconst WRITE_NOT_NEXT_TICK = MAX ^ WRITE_NEXT_TICK\nconst WRITE_NOT_UPDATING  = MAX ^ WRITE_UPDATING\nconst WRITE_NOT_CORKED    = MAX ^ WRITE_CORKED\n\n// Combined shared state\nconst ACTIVE = READ_ACTIVE | WRITE_ACTIVE\nconst NOT_ACTIVE = MAX ^ ACTIVE\nconst DONE = READ_DONE | WRITE_DONE\nconst DESTROY_STATUS = DESTROYING | DESTROYED | PREDESTROYING\nconst OPEN_STATUS = DESTROY_STATUS | OPENING\nconst AUTO_DESTROY = DESTROY_STATUS | DONE\nconst NON_PRIMARY = WRITE_NON_PRIMARY & READ_NON_PRIMARY\nconst ACTIVE_OR_TICKING = WRITE_NEXT_TICK | READ_NEXT_TICK\nconst TICKING = ACTIVE_OR_TICKING & NOT_ACTIVE\nconst IS_OPENING = OPEN_STATUS | TICKING\n\n// Combined shared state and read state\nconst READ_PRIMARY_STATUS = OPEN_STATUS | READ_ENDING | READ_DONE\nconst READ_STATUS = OPEN_STATUS | READ_DONE | READ_QUEUED\nconst READ_ENDING_STATUS = OPEN_STATUS | READ_ENDING | READ_QUEUED\nconst READ_READABLE_STATUS = OPEN_STATUS | READ_EMIT_READABLE | READ_QUEUED | READ_EMITTED_READABLE\nconst SHOULD_NOT_READ = OPEN_STATUS | READ_ACTIVE | READ_ENDING | READ_DONE | READ_NEEDS_PUSH | READ_READ_AHEAD\nconst READ_BACKPRESSURE_STATUS = DESTROY_STATUS | READ_ENDING | READ_DONE\nconst READ_UPDATE_SYNC_STATUS = READ_UPDATING | OPEN_STATUS | READ_NEXT_TICK | READ_PRIMARY\nconst READ_NEXT_TICK_OR_OPENING = READ_NEXT_TICK | OPENING\n\n// Combined write state\nconst WRITE_PRIMARY_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_QUEUED_AND_UNDRAINED = WRITE_QUEUED | WRITE_UNDRAINED\nconst WRITE_QUEUED_AND_ACTIVE = WRITE_QUEUED | WRITE_ACTIVE\nconst WRITE_DRAIN_STATUS = WRITE_QUEUED | WRITE_UNDRAINED | OPEN_STATUS | WRITE_ACTIVE\nconst WRITE_STATUS = OPEN_STATUS | WRITE_ACTIVE | WRITE_QUEUED | WRITE_CORKED\nconst WRITE_PRIMARY_AND_ACTIVE = WRITE_PRIMARY | WRITE_ACTIVE\nconst WRITE_ACTIVE_AND_WRITING = WRITE_ACTIVE | WRITE_WRITING\nconst WRITE_FINISHING_STATUS = OPEN_STATUS | WRITE_FINISHING | WRITE_QUEUED_AND_ACTIVE | WRITE_DONE\nconst WRITE_BACKPRESSURE_STATUS = WRITE_UNDRAINED | DESTROY_STATUS | WRITE_FINISHING | WRITE_DONE\nconst WRITE_UPDATE_SYNC_STATUS = WRITE_UPDATING | OPEN_STATUS | WRITE_NEXT_TICK | WRITE_PRIMARY\nconst WRITE_DROP_DATA = WRITE_FINISHING | WRITE_DONE | DESTROY_STATUS\n\nconst asyncIterator = Symbol.asyncIterator || Symbol('asyncIterator')\n\nclass WritableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapWritable, byteLength, byteLengthWritable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark\n    this.buffered = 0\n    this.error = null\n    this.pipeline = null\n    this.drains = null // if we add more seldomly used helpers we might them into a subobject so its a single ptr\n    this.byteLength = byteLengthWritable || byteLength || defaultByteLength\n    this.map = mapWritable || map\n    this.afterWrite = afterWrite.bind(this)\n    this.afterUpdateNextTick = updateWriteNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & WRITE_DONE) !== 0\n  }\n\n  push (data) {\n    if ((this.stream._duplexState & WRITE_DROP_DATA) !== 0) return false\n    if (this.map !== null) data = this.map(data)\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    if (this.buffered < this.highWaterMark) {\n      this.stream._duplexState |= WRITE_QUEUED\n      return true\n    }\n\n    this.stream._duplexState |= WRITE_QUEUED_AND_UNDRAINED\n    return false\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= WRITE_NOT_QUEUED\n\n    return data\n  }\n\n  end (data) {\n    if (typeof data === 'function') this.stream.once('finish', data)\n    else if (data !== undefined && data !== null) this.push(data)\n    this.stream._duplexState = (this.stream._duplexState | WRITE_FINISHING) & WRITE_NON_PRIMARY\n  }\n\n  autoBatch (data, cb) {\n    const buffer = []\n    const stream = this.stream\n\n    buffer.push(data)\n    while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED_AND_ACTIVE) {\n      buffer.push(stream._writableState.shift())\n    }\n\n    if ((stream._duplexState & OPEN_STATUS) !== 0) return cb(null)\n    stream._writev(buffer, cb)\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= WRITE_UPDATING\n\n    do {\n      while ((stream._duplexState & WRITE_STATUS) === WRITE_QUEUED) {\n        const data = this.shift()\n        stream._duplexState |= WRITE_ACTIVE_AND_WRITING\n        stream._write(data, this.afterWrite)\n      }\n\n      if ((stream._duplexState & WRITE_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= WRITE_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & WRITE_FINISHING_STATUS) === WRITE_FINISHING) {\n      stream._duplexState = stream._duplexState | WRITE_ACTIVE\n      stream._final(afterFinal.bind(this))\n      return\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & WRITE_UPDATE_SYNC_STATUS) === WRITE_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & WRITE_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= WRITE_NEXT_TICK\n    if ((this.stream._duplexState & WRITE_UPDATING) === 0) queueMicrotask(this.afterUpdateNextTick)\n  }\n}\n\nclass ReadableState {\n  constructor (stream, { highWaterMark = 16384, map = null, mapReadable, byteLength, byteLengthReadable } = {}) {\n    this.stream = stream\n    this.queue = new FIFO()\n    this.highWaterMark = highWaterMark === 0 ? 1 : highWaterMark\n    this.buffered = 0\n    this.readAhead = highWaterMark > 0\n    this.error = null\n    this.pipeline = null\n    this.byteLength = byteLengthReadable || byteLength || defaultByteLength\n    this.map = mapReadable || map\n    this.pipeTo = null\n    this.afterRead = afterRead.bind(this)\n    this.afterUpdateNextTick = updateReadNT.bind(this)\n  }\n\n  get ended () {\n    return (this.stream._duplexState & READ_DONE) !== 0\n  }\n\n  pipe (pipeTo, cb) {\n    if (this.pipeTo !== null) throw new Error('Can only pipe to one destination')\n    if (typeof cb !== 'function') cb = null\n\n    this.stream._duplexState |= READ_PIPE_DRAINED\n    this.pipeTo = pipeTo\n    this.pipeline = new Pipeline(this.stream, pipeTo, cb)\n\n    if (cb) this.stream.on('error', noop) // We already error handle this so supress crashes\n\n    if (isStreamx(pipeTo)) {\n      pipeTo._writableState.pipeline = this.pipeline\n      if (cb) pipeTo.on('error', noop) // We already error handle this so supress crashes\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline)) // TODO: just call finished from pipeTo itself\n    } else {\n      const onerror = this.pipeline.done.bind(this.pipeline, pipeTo)\n      const onclose = this.pipeline.done.bind(this.pipeline, pipeTo, null) // onclose has a weird bool arg\n      pipeTo.on('error', onerror)\n      pipeTo.on('close', onclose)\n      pipeTo.on('finish', this.pipeline.finished.bind(this.pipeline))\n    }\n\n    pipeTo.on('drain', afterDrain.bind(this))\n    this.stream.emit('piping', pipeTo)\n    pipeTo.emit('pipe', this.stream)\n  }\n\n  push (data) {\n    const stream = this.stream\n\n    if (data === null) {\n      this.highWaterMark = 0\n      stream._duplexState = (stream._duplexState | READ_ENDING) & READ_NON_PRIMARY_AND_PUSHED\n      return false\n    }\n\n    if (this.map !== null) {\n      data = this.map(data)\n      if (data === null) {\n        stream._duplexState &= READ_PUSHED\n        return this.buffered < this.highWaterMark\n      }\n    }\n\n    this.buffered += this.byteLength(data)\n    this.queue.push(data)\n\n    stream._duplexState = (stream._duplexState | READ_QUEUED) & READ_PUSHED\n\n    return this.buffered < this.highWaterMark\n  }\n\n  shift () {\n    const data = this.queue.shift()\n\n    this.buffered -= this.byteLength(data)\n    if (this.buffered === 0) this.stream._duplexState &= READ_NOT_QUEUED\n    return data\n  }\n\n  unshift (data) {\n    const pending = [this.map !== null ? this.map(data) : data]\n    while (this.buffered > 0) pending.push(this.shift())\n\n    for (let i = 0; i < pending.length - 1; i++) {\n      const data = pending[i]\n      this.buffered += this.byteLength(data)\n      this.queue.push(data)\n    }\n\n    this.push(pending[pending.length - 1])\n  }\n\n  read () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_STATUS) === READ_QUEUED) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n      return data\n    }\n\n    if (this.readAhead === false) {\n      stream._duplexState |= READ_READ_AHEAD\n      this.updateNextTick()\n    }\n\n    return null\n  }\n\n  drain () {\n    const stream = this.stream\n\n    while ((stream._duplexState & READ_STATUS) === READ_QUEUED && (stream._duplexState & READ_FLOWING) !== 0) {\n      const data = this.shift()\n      if (this.pipeTo !== null && this.pipeTo.write(data) === false) stream._duplexState &= READ_PIPE_NOT_DRAINED\n      if ((stream._duplexState & READ_EMIT_DATA) !== 0) stream.emit('data', data)\n    }\n  }\n\n  update () {\n    const stream = this.stream\n\n    stream._duplexState |= READ_UPDATING\n\n    do {\n      this.drain()\n\n      while (this.buffered < this.highWaterMark && (stream._duplexState & SHOULD_NOT_READ) === READ_READ_AHEAD) {\n        stream._duplexState |= READ_ACTIVE_AND_NEEDS_PUSH\n        stream._read(this.afterRead)\n        this.drain()\n      }\n\n      if ((stream._duplexState & READ_READABLE_STATUS) === READ_EMIT_READABLE_AND_QUEUED) {\n        stream._duplexState |= READ_EMITTED_READABLE\n        stream.emit('readable')\n      }\n\n      if ((stream._duplexState & READ_PRIMARY_AND_ACTIVE) === 0) this.updateNonPrimary()\n    } while (this.continueUpdate() === true)\n\n    stream._duplexState &= READ_NOT_UPDATING\n  }\n\n  updateNonPrimary () {\n    const stream = this.stream\n\n    if ((stream._duplexState & READ_ENDING_STATUS) === READ_ENDING) {\n      stream._duplexState = (stream._duplexState | READ_DONE) & READ_NOT_ENDING\n      stream.emit('end')\n      if ((stream._duplexState & AUTO_DESTROY) === DONE) stream._duplexState |= DESTROYING\n      if (this.pipeTo !== null) this.pipeTo.end()\n    }\n\n    if ((stream._duplexState & DESTROY_STATUS) === DESTROYING) {\n      if ((stream._duplexState & ACTIVE_OR_TICKING) === 0) {\n        stream._duplexState |= ACTIVE\n        stream._destroy(afterDestroy.bind(this))\n      }\n      return\n    }\n\n    if ((stream._duplexState & IS_OPENING) === OPENING) {\n      stream._duplexState = (stream._duplexState | ACTIVE) & NOT_OPENING\n      stream._open(afterOpen.bind(this))\n    }\n  }\n\n  continueUpdate () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) === 0) return false\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    return true\n  }\n\n  updateCallback () {\n    if ((this.stream._duplexState & READ_UPDATE_SYNC_STATUS) === READ_PRIMARY) this.update()\n    else this.updateNextTick()\n  }\n\n  updateNextTickIfOpen () {\n    if ((this.stream._duplexState & READ_NEXT_TICK_OR_OPENING) !== 0) return\n    this.stream._duplexState |= READ_NEXT_TICK\n    if ((this.stream._duplexState & READ_UPDATING) === 0) queueMicrotask(this.afterUpdateNextTick)\n  }\n\n  updateNextTick () {\n    if ((this.stream._duplexState & READ_NEXT_TICK) !== 0) return\n    this.stream._duplexState |= READ_NEXT_TICK\n    if ((this.stream._duplexState & READ_UPDATING) === 0) queueMicrotask(this.afterUpdateNextTick)\n  }\n}\n\nclass TransformState {\n  constructor (stream) {\n    this.data = null\n    this.afterTransform = afterTransform.bind(stream)\n    this.afterFinal = null\n  }\n}\n\nclass Pipeline {\n  constructor (src, dst, cb) {\n    this.from = src\n    this.to = dst\n    this.afterPipe = cb\n    this.error = null\n    this.pipeToFinished = false\n  }\n\n  finished () {\n    this.pipeToFinished = true\n  }\n\n  done (stream, err) {\n    if (err) this.error = err\n\n    if (stream === this.to) {\n      this.to = null\n\n      if (this.from !== null) {\n        if ((this.from._duplexState & READ_DONE) === 0 || !this.pipeToFinished) {\n          this.from.destroy(this.error || new Error('Writable stream closed prematurely'))\n        }\n        return\n      }\n    }\n\n    if (stream === this.from) {\n      this.from = null\n\n      if (this.to !== null) {\n        if ((stream._duplexState & READ_DONE) === 0) {\n          this.to.destroy(this.error || new Error('Readable stream closed before ending'))\n        }\n        return\n      }\n    }\n\n    if (this.afterPipe !== null) this.afterPipe(this.error)\n    this.to = this.from = this.afterPipe = null\n  }\n}\n\nfunction afterDrain () {\n  this.stream._duplexState |= READ_PIPE_DRAINED\n  this.updateCallback()\n}\n\nfunction afterFinal (err) {\n  const stream = this.stream\n  if (err) stream.destroy(err)\n  if ((stream._duplexState & DESTROY_STATUS) === 0) {\n    stream._duplexState |= WRITE_DONE\n    stream.emit('finish')\n  }\n  if ((stream._duplexState & AUTO_DESTROY) === DONE) {\n    stream._duplexState |= DESTROYING\n  }\n\n  stream._duplexState &= WRITE_NOT_FINISHING\n\n  // no need to wait the extra tick here, so we short circuit that\n  if ((stream._duplexState & WRITE_UPDATING) === 0) this.update()\n  else this.updateNextTick()\n}\n\nfunction afterDestroy (err) {\n  const stream = this.stream\n\n  if (!err && this.error !== STREAM_DESTROYED) err = this.error\n  if (err) stream.emit('error', err)\n  stream._duplexState |= DESTROYED\n  stream.emit('close')\n\n  const rs = stream._readableState\n  const ws = stream._writableState\n\n  if (rs !== null && rs.pipeline !== null) rs.pipeline.done(stream, err)\n\n  if (ws !== null) {\n    while (ws.drains !== null && ws.drains.length > 0) ws.drains.shift().resolve(false)\n    if (ws.pipeline !== null) ws.pipeline.done(stream, err)\n  }\n}\n\nfunction afterWrite (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n  stream._duplexState &= WRITE_NOT_ACTIVE\n\n  if (this.drains !== null) tickDrains(this.drains)\n\n  if ((stream._duplexState & WRITE_DRAIN_STATUS) === WRITE_UNDRAINED) {\n    stream._duplexState &= WRITE_DRAINED\n    if ((stream._duplexState & WRITE_EMIT_DRAIN) === WRITE_EMIT_DRAIN) {\n      stream.emit('drain')\n    }\n  }\n\n  this.updateCallback()\n}\n\nfunction afterRead (err) {\n  if (err) this.stream.destroy(err)\n  this.stream._duplexState &= READ_NOT_ACTIVE\n  if (this.readAhead === false && (this.stream._duplexState & READ_RESUMED) === 0) this.stream._duplexState &= READ_NO_READ_AHEAD\n  this.updateCallback()\n}\n\nfunction updateReadNT () {\n  if ((this.stream._duplexState & READ_UPDATING) === 0) {\n    this.stream._duplexState &= READ_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction updateWriteNT () {\n  if ((this.stream._duplexState & WRITE_UPDATING) === 0) {\n    this.stream._duplexState &= WRITE_NOT_NEXT_TICK\n    this.update()\n  }\n}\n\nfunction tickDrains (drains) {\n  for (let i = 0; i < drains.length; i++) {\n    // drains.writes are monotonic, so if one is 0 its always the first one\n    if (--drains[i].writes === 0) {\n      drains.shift().resolve(true)\n      i--\n    }\n  }\n}\n\nfunction afterOpen (err) {\n  const stream = this.stream\n\n  if (err) stream.destroy(err)\n\n  if ((stream._duplexState & DESTROYING) === 0) {\n    if ((stream._duplexState & READ_PRIMARY_STATUS) === 0) stream._duplexState |= READ_PRIMARY\n    if ((stream._duplexState & WRITE_PRIMARY_STATUS) === 0) stream._duplexState |= WRITE_PRIMARY\n    stream.emit('open')\n  }\n\n  stream._duplexState &= NOT_ACTIVE\n\n  if (stream._writableState !== null) {\n    stream._writableState.updateCallback()\n  }\n\n  if (stream._readableState !== null) {\n    stream._readableState.updateCallback()\n  }\n}\n\nfunction afterTransform (err, data) {\n  if (data !== undefined && data !== null) this.push(data)\n  this._writableState.afterWrite(err)\n}\n\nfunction newListener (name) {\n  if (this._readableState !== null) {\n    if (name === 'data') {\n      this._duplexState |= (READ_EMIT_DATA | READ_RESUMED_READ_AHEAD)\n      this._readableState.updateNextTick()\n    }\n    if (name === 'readable') {\n      this._duplexState |= READ_EMIT_READABLE\n      this._readableState.updateNextTick()\n    }\n  }\n\n  if (this._writableState !== null) {\n    if (name === 'drain') {\n      this._duplexState |= WRITE_EMIT_DRAIN\n      this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Stream extends EventEmitter {\n  constructor (opts) {\n    super()\n\n    this._duplexState = 0\n    this._readableState = null\n    this._writableState = null\n\n    if (opts) {\n      if (opts.open) this._open = opts.open\n      if (opts.destroy) this._destroy = opts.destroy\n      if (opts.predestroy) this._predestroy = opts.predestroy\n      if (opts.signal) {\n        opts.signal.addEventListener('abort', abort.bind(this))\n      }\n    }\n\n    this.on('newListener', newListener)\n  }\n\n  _open (cb) {\n    cb(null)\n  }\n\n  _destroy (cb) {\n    cb(null)\n  }\n\n  _predestroy () {\n    // does nothing\n  }\n\n  get readable () {\n    return this._readableState !== null ? true : undefined\n  }\n\n  get writable () {\n    return this._writableState !== null ? true : undefined\n  }\n\n  get destroyed () {\n    return (this._duplexState & DESTROYED) !== 0\n  }\n\n  get destroying () {\n    return (this._duplexState & DESTROY_STATUS) !== 0\n  }\n\n  destroy (err) {\n    if ((this._duplexState & DESTROY_STATUS) === 0) {\n      if (!err) err = STREAM_DESTROYED\n      this._duplexState = (this._duplexState | DESTROYING) & NON_PRIMARY\n\n      if (this._readableState !== null) {\n        this._readableState.highWaterMark = 0\n        this._readableState.error = err\n      }\n      if (this._writableState !== null) {\n        this._writableState.highWaterMark = 0\n        this._writableState.error = err\n      }\n\n      this._duplexState |= PREDESTROYING\n      this._predestroy()\n      this._duplexState &= NOT_PREDESTROYING\n\n      if (this._readableState !== null) this._readableState.updateNextTick()\n      if (this._writableState !== null) this._writableState.updateNextTick()\n    }\n  }\n}\n\nclass Readable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | WRITE_DONE | READ_READ_AHEAD\n    this._readableState = new ReadableState(this, opts)\n\n    if (opts) {\n      if (this._readableState.readAhead === false) this._duplexState &= READ_NO_READ_AHEAD\n      if (opts.read) this._read = opts.read\n      if (opts.eagerOpen) this._readableState.updateNextTick()\n      if (opts.encoding) this.setEncoding(opts.encoding)\n    }\n  }\n\n  setEncoding (encoding) {\n    const dec = new TextDecoder(encoding)\n    const map = this._readableState.map || echo\n    this._readableState.map = mapOrSkip\n    return this\n\n    function mapOrSkip (data) {\n      const next = dec.push(data)\n      return next === '' && (data.byteLength !== 0 || dec.remaining > 0) ? null : map(next)\n    }\n  }\n\n  _read (cb) {\n    cb(null)\n  }\n\n  pipe (dest, cb) {\n    this._readableState.updateNextTick()\n    this._readableState.pipe(dest, cb)\n    return dest\n  }\n\n  read () {\n    this._readableState.updateNextTick()\n    return this._readableState.read()\n  }\n\n  push (data) {\n    this._readableState.updateNextTickIfOpen()\n    return this._readableState.push(data)\n  }\n\n  unshift (data) {\n    this._readableState.updateNextTickIfOpen()\n    return this._readableState.unshift(data)\n  }\n\n  resume () {\n    this._duplexState |= READ_RESUMED_READ_AHEAD\n    this._readableState.updateNextTick()\n    return this\n  }\n\n  pause () {\n    this._duplexState &= (this._readableState.readAhead === false ? READ_PAUSED_NO_READ_AHEAD : READ_PAUSED)\n    return this\n  }\n\n  static _fromAsyncIterator (ite, opts) {\n    let destroy\n\n    const rs = new Readable({\n      ...opts,\n      read (cb) {\n        ite.next().then(push).then(cb.bind(null, null)).catch(cb)\n      },\n      predestroy () {\n        destroy = ite.return()\n      },\n      destroy (cb) {\n        if (!destroy) return cb(null)\n        destroy.then(cb.bind(null, null)).catch(cb)\n      }\n    })\n\n    return rs\n\n    function push (data) {\n      if (data.done) rs.push(null)\n      else rs.push(data.value)\n    }\n  }\n\n  static from (data, opts) {\n    if (isReadStreamx(data)) return data\n    if (data[asyncIterator]) return this._fromAsyncIterator(data[asyncIterator](), opts)\n    if (!Array.isArray(data)) data = data === undefined ? [] : [data]\n\n    let i = 0\n    return new Readable({\n      ...opts,\n      read (cb) {\n        this.push(i === data.length ? null : data[i++])\n        cb(null)\n      }\n    })\n  }\n\n  static isBackpressured (rs) {\n    return (rs._duplexState & READ_BACKPRESSURE_STATUS) !== 0 || rs._readableState.buffered >= rs._readableState.highWaterMark\n  }\n\n  static isPaused (rs) {\n    return (rs._duplexState & READ_RESUMED) === 0\n  }\n\n  [asyncIterator] () {\n    const stream = this\n\n    let error = null\n    let promiseResolve = null\n    let promiseReject = null\n\n    this.on('error', (err) => { error = err })\n    this.on('readable', onreadable)\n    this.on('close', onclose)\n\n    return {\n      [asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(function (resolve, reject) {\n          promiseResolve = resolve\n          promiseReject = reject\n          const data = stream.read()\n          if (data !== null) ondata(data)\n          else if ((stream._duplexState & DESTROYED) !== 0) ondata(null)\n        })\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function onreadable () {\n      if (promiseResolve !== null) ondata(stream.read())\n    }\n\n    function onclose () {\n      if (promiseResolve !== null) ondata(null)\n    }\n\n    function ondata (data) {\n      if (promiseReject === null) return\n      if (error) promiseReject(error)\n      else if (data === null && (stream._duplexState & READ_DONE) === 0) promiseReject(STREAM_DESTROYED)\n      else promiseResolve({ value: data, done: data === null })\n      promiseReject = promiseResolve = null\n    }\n\n    function destroy (err) {\n      stream.destroy(err)\n      return new Promise((resolve, reject) => {\n        if (stream._duplexState & DESTROYED) return resolve({ value: undefined, done: true })\n        stream.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nclass Writable extends Stream {\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState |= OPENING | READ_DONE\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n      if (opts.eagerOpen) this._writableState.updateNextTick()\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  static isBackpressured (ws) {\n    return (ws._duplexState & WRITE_BACKPRESSURE_STATUS) !== 0\n  }\n\n  static drained (ws) {\n    if (ws.destroyed) return Promise.resolve(false)\n    const state = ws._writableState\n    const pending = (isWritev(ws) ? Math.min(1, state.queue.length) : state.queue.length)\n    const writes = pending + ((ws._duplexState & WRITE_WRITING) ? 1 : 0)\n    if (writes === 0) return Promise.resolve(true)\n    if (state.drains === null) state.drains = []\n    return new Promise((resolve) => {\n      state.drains.push({ writes, resolve })\n    })\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Duplex extends Readable { // and Writable\n  constructor (opts) {\n    super(opts)\n\n    this._duplexState = OPENING | (this._duplexState & READ_READ_AHEAD)\n    this._writableState = new WritableState(this, opts)\n\n    if (opts) {\n      if (opts.writev) this._writev = opts.writev\n      if (opts.write) this._write = opts.write\n      if (opts.final) this._final = opts.final\n    }\n  }\n\n  cork () {\n    this._duplexState |= WRITE_CORKED\n  }\n\n  uncork () {\n    this._duplexState &= WRITE_NOT_CORKED\n    this._writableState.updateNextTick()\n  }\n\n  _writev (batch, cb) {\n    cb(null)\n  }\n\n  _write (data, cb) {\n    this._writableState.autoBatch(data, cb)\n  }\n\n  _final (cb) {\n    cb(null)\n  }\n\n  write (data) {\n    this._writableState.updateNextTick()\n    return this._writableState.push(data)\n  }\n\n  end (data) {\n    this._writableState.updateNextTick()\n    this._writableState.end(data)\n    return this\n  }\n}\n\nclass Transform extends Duplex {\n  constructor (opts) {\n    super(opts)\n    this._transformState = new TransformState(this)\n\n    if (opts) {\n      if (opts.transform) this._transform = opts.transform\n      if (opts.flush) this._flush = opts.flush\n    }\n  }\n\n  _write (data, cb) {\n    if (this._readableState.buffered >= this._readableState.highWaterMark) {\n      this._transformState.data = data\n    } else {\n      this._transform(data, this._transformState.afterTransform)\n    }\n  }\n\n  _read (cb) {\n    if (this._transformState.data !== null) {\n      const data = this._transformState.data\n      this._transformState.data = null\n      cb(null)\n      this._transform(data, this._transformState.afterTransform)\n    } else {\n      cb(null)\n    }\n  }\n\n  destroy (err) {\n    super.destroy(err)\n    if (this._transformState.data !== null) {\n      this._transformState.data = null\n      this._transformState.afterTransform()\n    }\n  }\n\n  _transform (data, cb) {\n    cb(null, data)\n  }\n\n  _flush (cb) {\n    cb(null)\n  }\n\n  _final (cb) {\n    this._transformState.afterFinal = cb\n    this._flush(transformAfterFlush.bind(this))\n  }\n}\n\nclass PassThrough extends Transform {}\n\nfunction transformAfterFlush (err, data) {\n  const cb = this._transformState.afterFinal\n  if (err) return cb(err)\n  if (data !== null && data !== undefined) this.push(data)\n  this.push(null)\n  cb(null)\n}\n\nfunction pipelinePromise (...streams) {\n  return new Promise((resolve, reject) => {\n    return pipeline(...streams, (err) => {\n      if (err) return reject(err)\n      resolve()\n    })\n  })\n}\n\nfunction pipeline (stream, ...streams) {\n  const all = Array.isArray(stream) ? [...stream, ...streams] : [stream, ...streams]\n  const done = (all.length && typeof all[all.length - 1] === 'function') ? all.pop() : null\n\n  if (all.length < 2) throw new Error('Pipeline requires at least 2 streams')\n\n  let src = all[0]\n  let dest = null\n  let error = null\n\n  for (let i = 1; i < all.length; i++) {\n    dest = all[i]\n\n    if (isStreamx(src)) {\n      src.pipe(dest, onerror)\n    } else {\n      errorHandle(src, true, i > 1, onerror)\n      src.pipe(dest)\n    }\n\n    src = dest\n  }\n\n  if (done) {\n    let fin = false\n\n    const autoDestroy = isStreamx(dest) || !!(dest._writableState && dest._writableState.autoDestroy)\n\n    dest.on('error', (err) => {\n      if (error === null) error = err\n    })\n\n    dest.on('finish', () => {\n      fin = true\n      if (!autoDestroy) done(error)\n    })\n\n    if (autoDestroy) {\n      dest.on('close', () => done(error || (fin ? null : PREMATURE_CLOSE)))\n    }\n  }\n\n  return dest\n\n  function errorHandle (s, rd, wr, onerror) {\n    s.on('error', onerror)\n    s.on('close', onclose)\n\n    function onclose () {\n      if (rd && s._readableState && !s._readableState.ended) return onerror(PREMATURE_CLOSE)\n      if (wr && s._writableState && !s._writableState.ended) return onerror(PREMATURE_CLOSE)\n    }\n  }\n\n  function onerror (err) {\n    if (!err || error) return\n    error = err\n\n    for (const s of all) {\n      s.destroy(err)\n    }\n  }\n}\n\nfunction echo (s) {\n  return s\n}\n\nfunction isStream (stream) {\n  return !!stream._readableState || !!stream._writableState\n}\n\nfunction isStreamx (stream) {\n  return typeof stream._duplexState === 'number' && isStream(stream)\n}\n\nfunction isEnded (stream) {\n  return !!stream._readableState && stream._readableState.ended\n}\n\nfunction isFinished (stream) {\n  return !!stream._writableState && stream._writableState.ended\n}\n\nfunction getStreamError (stream, opts = {}) {\n  const err = (stream._readableState && stream._readableState.error) || (stream._writableState && stream._writableState.error)\n\n  // avoid implicit errors by default\n  return (!opts.all && err === STREAM_DESTROYED) ? null : err\n}\n\nfunction isReadStreamx (stream) {\n  return isStreamx(stream) && stream.readable\n}\n\nfunction isDisturbed (stream) {\n  return (stream._duplexState & OPENING) !== OPENING || (stream._duplexState & ACTIVE_OR_TICKING) !== 0\n}\n\nfunction isTypedArray (data) {\n  return typeof data === 'object' && data !== null && typeof data.byteLength === 'number'\n}\n\nfunction defaultByteLength (data) {\n  return isTypedArray(data) ? data.byteLength : 1024\n}\n\nfunction noop () {}\n\nfunction abort () {\n  this.destroy(new Error('Stream aborted.'))\n}\n\nfunction isWritev (s) {\n  return s._writev !== Writable.prototype._writev && s._writev !== Duplex.prototype._writev\n}\n\nmodule.exports = {\n  pipeline,\n  pipelinePromise,\n  isStream,\n  isStreamx,\n  isEnded,\n  isFinished,\n  isDisturbed,\n  getStreamError,\n  Stream,\n  Writable,\n  Readable,\n  Duplex,\n  Transform,\n  // Export PassThrough for compatibility with Node.js core's stream module\n  PassThrough\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/streamx/index.js?");

/***/ }),

/***/ "./node_modules/tar-fs/index.js":
/*!**************************************!*\
  !*** ./node_modules/tar-fs/index.js ***!
  \**************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const tar = __webpack_require__(/*! tar-stream */ \"./node_modules/tar-stream/index.js\")\nconst pump = __webpack_require__(/*! pump */ \"./node_modules/pump/index.js\")\nconst fs = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'fs'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\nconst path = __webpack_require__(Object(function webpackMissingModule() { var e = new Error(\"Cannot find module 'path'\"); e.code = 'MODULE_NOT_FOUND'; throw e; }()))\n\nconst win32 = (__webpack_require__.g.Bare?.platform || process.platform) === 'win32'\n\nexports.pack = function pack (cwd, opts) {\n  if (!cwd) cwd = '.'\n  if (!opts) opts = {}\n\n  const xfs = opts.fs || fs\n  const ignore = opts.ignore || opts.filter || noop\n  const mapStream = opts.mapStream || echo\n  const statNext = statAll(xfs, opts.dereference ? xfs.stat : xfs.lstat, cwd, ignore, opts.entries, opts.sort)\n  const strict = opts.strict !== false\n  const umask = typeof opts.umask === 'number' ? ~opts.umask : ~processUmask()\n  const pack = opts.pack || tar.pack()\n  const finish = opts.finish || noop\n\n  let map = opts.map || noop\n  let dmode = typeof opts.dmode === 'number' ? opts.dmode : 0\n  let fmode = typeof opts.fmode === 'number' ? opts.fmode : 0\n\n  if (opts.strip) map = strip(map, opts.strip)\n\n  if (opts.readable) {\n    dmode |= parseInt(555, 8)\n    fmode |= parseInt(444, 8)\n  }\n  if (opts.writable) {\n    dmode |= parseInt(333, 8)\n    fmode |= parseInt(222, 8)\n  }\n\n  onnextentry()\n\n  function onsymlink (filename, header) {\n    xfs.readlink(path.join(cwd, filename), function (err, linkname) {\n      if (err) return pack.destroy(err)\n      header.linkname = normalize(linkname)\n      pack.entry(header, onnextentry)\n    })\n  }\n\n  function onstat (err, filename, stat) {\n    if (pack.destroyed) return\n    if (err) return pack.destroy(err)\n    if (!filename) {\n      if (opts.finalize !== false) pack.finalize()\n      return finish(pack)\n    }\n\n    if (stat.isSocket()) return onnextentry() // tar does not support sockets...\n\n    let header = {\n      name: normalize(filename),\n      mode: (stat.mode | (stat.isDirectory() ? dmode : fmode)) & umask,\n      mtime: stat.mtime,\n      size: stat.size,\n      type: 'file',\n      uid: stat.uid,\n      gid: stat.gid\n    }\n\n    if (stat.isDirectory()) {\n      header.size = 0\n      header.type = 'directory'\n      header = map(header) || header\n      return pack.entry(header, onnextentry)\n    }\n\n    if (stat.isSymbolicLink()) {\n      header.size = 0\n      header.type = 'symlink'\n      header = map(header) || header\n      return onsymlink(filename, header)\n    }\n\n    // TODO: add fifo etc...\n\n    header = map(header) || header\n\n    if (!stat.isFile()) {\n      if (strict) return pack.destroy(new Error('unsupported type for ' + filename))\n      return onnextentry()\n    }\n\n    const entry = pack.entry(header, onnextentry)\n    const rs = mapStream(xfs.createReadStream(path.join(cwd, filename), { start: 0, end: header.size > 0 ? header.size - 1 : header.size }), header)\n\n    rs.on('error', function (err) { // always forward errors on destroy\n      entry.destroy(err)\n    })\n\n    pump(rs, entry)\n  }\n\n  function onnextentry (err) {\n    if (err) return pack.destroy(err)\n    statNext(onstat)\n  }\n\n  return pack\n}\n\nfunction head (list) {\n  return list.length ? list[list.length - 1] : null\n}\n\nfunction processGetuid () {\n  return process.getuid ? process.getuid() : -1\n}\n\nfunction processUmask () {\n  return process.umask ? process.umask() : 0\n}\n\nexports.extract = function extract (cwd, opts) {\n  if (!cwd) cwd = '.'\n  if (!opts) opts = {}\n\n  cwd = path.resolve(cwd)\n\n  const xfs = opts.fs || fs\n  const ignore = opts.ignore || opts.filter || noop\n  const mapStream = opts.mapStream || echo\n  const own = opts.chown !== false && !win32 && processGetuid() === 0\n  const extract = opts.extract || tar.extract()\n  const stack = []\n  const now = new Date()\n  const umask = typeof opts.umask === 'number' ? ~opts.umask : ~processUmask()\n  const strict = opts.strict !== false\n\n  let map = opts.map || noop\n  let dmode = typeof opts.dmode === 'number' ? opts.dmode : 0\n  let fmode = typeof opts.fmode === 'number' ? opts.fmode : 0\n\n  if (opts.strip) map = strip(map, opts.strip)\n\n  if (opts.readable) {\n    dmode |= parseInt(555, 8)\n    fmode |= parseInt(444, 8)\n  }\n  if (opts.writable) {\n    dmode |= parseInt(333, 8)\n    fmode |= parseInt(222, 8)\n  }\n\n  extract.on('entry', onentry)\n\n  if (opts.finish) extract.on('finish', opts.finish)\n\n  return extract\n\n  function onentry (header, stream, next) {\n    header = map(header) || header\n    header.name = normalize(header.name)\n\n    const name = path.join(cwd, path.join('/', header.name))\n\n    if (ignore(name, header)) {\n      stream.resume()\n      return next()\n    }\n\n    if (header.type === 'directory') {\n      stack.push([name, header.mtime])\n      return mkdirfix(name, {\n        fs: xfs,\n        own,\n        uid: header.uid,\n        gid: header.gid,\n        mode: header.mode\n      }, stat)\n    }\n\n    const dir = path.dirname(name)\n\n    validate(xfs, dir, path.join(cwd, '.'), function (err, valid) {\n      if (err) return next(err)\n      if (!valid) return next(new Error(dir + ' is not a valid path'))\n\n      mkdirfix(dir, {\n        fs: xfs,\n        own,\n        uid: header.uid,\n        gid: header.gid,\n        // normally, the folders with rights and owner should be part of the TAR file\n        // if this is not the case, create folder for same user as file and with\n        // standard permissions of 0o755 (rwxr-xr-x)\n        mode: 0o755\n      }, function (err) {\n        if (err) return next(err)\n\n        switch (header.type) {\n          case 'file': return onfile()\n          case 'link': return onlink()\n          case 'symlink': return onsymlink()\n        }\n\n        if (strict) return next(new Error('unsupported type for ' + name + ' (' + header.type + ')'))\n\n        stream.resume()\n        next()\n      })\n    })\n\n    function stat (err) {\n      if (err) return next(err)\n      utimes(name, header, function (err) {\n        if (err) return next(err)\n        if (win32) return next()\n        chperm(name, header, next)\n      })\n    }\n\n    function onsymlink () {\n      if (win32) return next() // skip symlinks on win for now before it can be tested\n      xfs.unlink(name, function () {\n        const dst = path.resolve(path.dirname(name), header.linkname)\n        if (!inCwd(dst)) return next(new Error(name + ' is not a valid symlink'))\n\n        xfs.symlink(header.linkname, name, stat)\n      })\n    }\n\n    function onlink () {\n      if (win32) return next() // skip links on win for now before it can be tested\n      xfs.unlink(name, function () {\n        const dst = path.join(cwd, path.join('/', header.linkname))\n\n        xfs.link(dst, name, function (err) {\n          if (err && err.code === 'EPERM' && opts.hardlinkAsFilesFallback) {\n            stream = xfs.createReadStream(dst)\n            return onfile()\n          }\n\n          stat(err)\n        })\n      })\n    }\n\n    function inCwd (dst) {\n      return dst.startsWith(cwd)\n    }\n\n    function onfile () {\n      const ws = xfs.createWriteStream(name)\n      const rs = mapStream(stream, header)\n\n      ws.on('error', function (err) { // always forward errors on destroy\n        rs.destroy(err)\n      })\n\n      pump(rs, ws, function (err) {\n        if (err) return next(err)\n        ws.on('close', stat)\n      })\n    }\n  }\n\n  function utimesParent (name, cb) { // we just set the mtime on the parent dir again everytime we write an entry\n    let top\n    while ((top = head(stack)) && name.slice(0, top[0].length) !== top[0]) stack.pop()\n    if (!top) return cb()\n    xfs.utimes(top[0], now, top[1], cb)\n  }\n\n  function utimes (name, header, cb) {\n    if (opts.utimes === false) return cb()\n\n    if (header.type === 'directory') return xfs.utimes(name, now, header.mtime, cb)\n    if (header.type === 'symlink') return utimesParent(name, cb) // TODO: how to set mtime on link?\n\n    xfs.utimes(name, now, header.mtime, function (err) {\n      if (err) return cb(err)\n      utimesParent(name, cb)\n    })\n  }\n\n  function chperm (name, header, cb) {\n    const link = header.type === 'symlink'\n\n    /* eslint-disable n/no-deprecated-api */\n    const chmod = link ? xfs.lchmod : xfs.chmod\n    const chown = link ? xfs.lchown : xfs.chown\n    /* eslint-enable n/no-deprecated-api */\n\n    if (!chmod) return cb()\n\n    const mode = (header.mode | (header.type === 'directory' ? dmode : fmode)) & umask\n\n    if (chown && own) chown.call(xfs, name, header.uid, header.gid, onchown)\n    else onchown(null)\n\n    function onchown (err) {\n      if (err) return cb(err)\n      if (!chmod) return cb()\n      chmod.call(xfs, name, mode, cb)\n    }\n  }\n\n  function mkdirfix (name, opts, cb) {\n    // when mkdir is called on an existing directory, the permissions\n    // will be overwritten (?), to avoid this we check for its existance first\n    xfs.stat(name, function (err) {\n      if (!err) return cb(null)\n      if (err.code !== 'ENOENT') return cb(err)\n      xfs.mkdir(name, { mode: opts.mode, recursive: true }, function (err, made) {\n        if (err) return cb(err)\n        chperm(name, opts, cb)\n      })\n    })\n  }\n}\n\nfunction validate (fs, name, root, cb) {\n  if (name === root) return cb(null, true)\n  fs.lstat(name, function (err, st) {\n    if (err && err.code === 'ENOENT') return validate(fs, path.join(name, '..'), root, cb)\n    else if (err) return cb(err)\n    cb(null, st.isDirectory())\n  })\n}\n\nfunction noop () {}\n\nfunction echo (name) {\n  return name\n}\n\nfunction normalize (name) {\n  return win32 ? name.replace(/\\\\/g, '/').replace(/[:?<>|]/g, '_') : name\n}\n\nfunction statAll (fs, stat, cwd, ignore, entries, sort) {\n  if (!entries) entries = ['.']\n  const queue = entries.slice(0)\n\n  return function loop (callback) {\n    if (!queue.length) return callback(null)\n\n    const next = queue.shift()\n    const nextAbs = path.join(cwd, next)\n\n    stat.call(fs, nextAbs, function (err, stat) {\n      // ignore errors if the files were deleted while buffering\n      if (err) return callback(entries.indexOf(next) === -1 && err.code === 'ENOENT' ? null : err)\n\n      if (!stat.isDirectory()) return callback(null, next, stat)\n\n      fs.readdir(nextAbs, function (err, files) {\n        if (err) return callback(err)\n\n        if (sort) files.sort()\n\n        for (let i = 0; i < files.length; i++) {\n          if (!ignore(path.join(cwd, next, files[i]))) queue.push(path.join(next, files[i]))\n        }\n\n        callback(null, next, stat)\n      })\n    })\n  }\n}\n\nfunction strip (map, level) {\n  return function (header) {\n    header.name = header.name.split('/').slice(level).join('/')\n\n    const linkname = header.linkname\n    if (linkname && (header.type === 'link' || path.isAbsolute(linkname))) {\n      header.linkname = linkname.split('/').slice(level).join('/')\n    }\n\n    return map(header)\n  }\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-fs/index.js?");

/***/ }),

/***/ "./node_modules/tar-stream/constants.js":
/*!**********************************************!*\
  !*** ./node_modules/tar-stream/constants.js ***!
  \**********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const constants = { // just for envs without fs\n  S_IFMT: 61440,\n  S_IFDIR: 16384,\n  S_IFCHR: 8192,\n  S_IFBLK: 24576,\n  S_IFIFO: 4096,\n  S_IFLNK: 40960\n}\n\ntry {\n  module.exports = (__webpack_require__(/*! fs */ \"?08ee\").constants) || constants\n} catch {\n  module.exports = constants\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-stream/constants.js?");

/***/ }),

/***/ "./node_modules/tar-stream/extract.js":
/*!********************************************!*\
  !*** ./node_modules/tar-stream/extract.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { Writable, Readable, getStreamError } = __webpack_require__(/*! streamx */ \"./node_modules/streamx/index.js\")\nconst FIFO = __webpack_require__(/*! fast-fifo */ \"./node_modules/fast-fifo/index.js\")\nconst b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\nconst headers = __webpack_require__(/*! ./headers */ \"./node_modules/tar-stream/headers.js\")\n\nconst EMPTY = b4a.alloc(0)\n\nclass BufferList {\n  constructor () {\n    this.buffered = 0\n    this.shifted = 0\n    this.queue = new FIFO()\n\n    this._offset = 0\n  }\n\n  push (buffer) {\n    this.buffered += buffer.byteLength\n    this.queue.push(buffer)\n  }\n\n  shiftFirst (size) {\n    return this._buffered === 0 ? null : this._next(size)\n  }\n\n  shift (size) {\n    if (size > this.buffered) return null\n    if (size === 0) return EMPTY\n\n    let chunk = this._next(size)\n\n    if (size === chunk.byteLength) return chunk // likely case\n\n    const chunks = [chunk]\n\n    while ((size -= chunk.byteLength) > 0) {\n      chunk = this._next(size)\n      chunks.push(chunk)\n    }\n\n    return b4a.concat(chunks)\n  }\n\n  _next (size) {\n    const buf = this.queue.peek()\n    const rem = buf.byteLength - this._offset\n\n    if (size >= rem) {\n      const sub = this._offset ? buf.subarray(this._offset, buf.byteLength) : buf\n      this.queue.shift()\n      this._offset = 0\n      this.buffered -= rem\n      this.shifted += rem\n      return sub\n    }\n\n    this.buffered -= size\n    this.shifted += size\n\n    return buf.subarray(this._offset, (this._offset += size))\n  }\n}\n\nclass Source extends Readable {\n  constructor (self, header, offset) {\n    super()\n\n    this.header = header\n    this.offset = offset\n\n    this._parent = self\n  }\n\n  _read (cb) {\n    if (this.header.size === 0) {\n      this.push(null)\n    }\n    if (this._parent._stream === this) {\n      this._parent._update()\n    }\n    cb(null)\n  }\n\n  _predestroy () {\n    this._parent.destroy(getStreamError(this))\n  }\n\n  _detach () {\n    if (this._parent._stream === this) {\n      this._parent._stream = null\n      this._parent._missing = overflow(this.header.size)\n      this._parent._update()\n    }\n  }\n\n  _destroy (cb) {\n    this._detach()\n    cb(null)\n  }\n}\n\nclass Extract extends Writable {\n  constructor (opts) {\n    super(opts)\n\n    if (!opts) opts = {}\n\n    this._buffer = new BufferList()\n    this._offset = 0\n    this._header = null\n    this._stream = null\n    this._missing = 0\n    this._longHeader = false\n    this._callback = noop\n    this._locked = false\n    this._finished = false\n    this._pax = null\n    this._paxGlobal = null\n    this._gnuLongPath = null\n    this._gnuLongLinkPath = null\n    this._filenameEncoding = opts.filenameEncoding || 'utf-8'\n    this._allowUnknownFormat = !!opts.allowUnknownFormat\n    this._unlockBound = this._unlock.bind(this)\n  }\n\n  _unlock (err) {\n    this._locked = false\n\n    if (err) {\n      this.destroy(err)\n      this._continueWrite(err)\n      return\n    }\n\n    this._update()\n  }\n\n  _consumeHeader () {\n    if (this._locked) return false\n\n    this._offset = this._buffer.shifted\n\n    try {\n      this._header = headers.decode(this._buffer.shift(512), this._filenameEncoding, this._allowUnknownFormat)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    if (!this._header) return true\n\n    switch (this._header.type) {\n      case 'gnu-long-path':\n      case 'gnu-long-link-path':\n      case 'pax-global-header':\n      case 'pax-header':\n        this._longHeader = true\n        this._missing = this._header.size\n        return true\n    }\n\n    this._locked = true\n    this._applyLongHeaders()\n\n    if (this._header.size === 0 || this._header.type === 'directory') {\n      this.emit('entry', this._header, this._createStream(), this._unlockBound)\n      return true\n    }\n\n    this._stream = this._createStream()\n    this._missing = this._header.size\n\n    this.emit('entry', this._header, this._stream, this._unlockBound)\n    return true\n  }\n\n  _applyLongHeaders () {\n    if (this._gnuLongPath) {\n      this._header.name = this._gnuLongPath\n      this._gnuLongPath = null\n    }\n\n    if (this._gnuLongLinkPath) {\n      this._header.linkname = this._gnuLongLinkPath\n      this._gnuLongLinkPath = null\n    }\n\n    if (this._pax) {\n      if (this._pax.path) this._header.name = this._pax.path\n      if (this._pax.linkpath) this._header.linkname = this._pax.linkpath\n      if (this._pax.size) this._header.size = parseInt(this._pax.size, 10)\n      this._header.pax = this._pax\n      this._pax = null\n    }\n  }\n\n  _decodeLongHeader (buf) {\n    switch (this._header.type) {\n      case 'gnu-long-path':\n        this._gnuLongPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'gnu-long-link-path':\n        this._gnuLongLinkPath = headers.decodeLongPath(buf, this._filenameEncoding)\n        break\n      case 'pax-global-header':\n        this._paxGlobal = headers.decodePax(buf)\n        break\n      case 'pax-header':\n        this._pax = this._paxGlobal === null\n          ? headers.decodePax(buf)\n          : Object.assign({}, this._paxGlobal, headers.decodePax(buf))\n        break\n    }\n  }\n\n  _consumeLongHeader () {\n    this._longHeader = false\n    this._missing = overflow(this._header.size)\n\n    const buf = this._buffer.shift(this._header.size)\n\n    try {\n      this._decodeLongHeader(buf)\n    } catch (err) {\n      this._continueWrite(err)\n      return false\n    }\n\n    return true\n  }\n\n  _consumeStream () {\n    const buf = this._buffer.shiftFirst(this._missing)\n    if (buf === null) return false\n\n    this._missing -= buf.byteLength\n    const drained = this._stream.push(buf)\n\n    if (this._missing === 0) {\n      this._stream.push(null)\n      if (drained) this._stream._detach()\n      return drained && this._locked === false\n    }\n\n    return drained\n  }\n\n  _createStream () {\n    return new Source(this, this._header, this._offset)\n  }\n\n  _update () {\n    while (this._buffer.buffered > 0 && !this.destroying) {\n      if (this._missing > 0) {\n        if (this._stream !== null) {\n          if (this._consumeStream() === false) return\n          continue\n        }\n\n        if (this._longHeader === true) {\n          if (this._missing > this._buffer.buffered) break\n          if (this._consumeLongHeader() === false) return false\n          continue\n        }\n\n        const ignore = this._buffer.shiftFirst(this._missing)\n        if (ignore !== null) this._missing -= ignore.byteLength\n        continue\n      }\n\n      if (this._buffer.buffered < 512) break\n      if (this._stream !== null || this._consumeHeader() === false) return\n    }\n\n    this._continueWrite(null)\n  }\n\n  _continueWrite (err) {\n    const cb = this._callback\n    this._callback = noop\n    cb(err)\n  }\n\n  _write (data, cb) {\n    this._callback = cb\n    this._buffer.push(data)\n    this._update()\n  }\n\n  _final (cb) {\n    this._finished = this._missing === 0 && this._buffer.buffered === 0\n    cb(this._finished ? null : new Error('Unexpected end of data'))\n  }\n\n  _predestroy () {\n    this._continueWrite(null)\n  }\n\n  _destroy (cb) {\n    if (this._stream) this._stream.destroy(getStreamError(this))\n    cb(null)\n  }\n\n  [Symbol.asyncIterator] () {\n    let error = null\n\n    let promiseResolve = null\n    let promiseReject = null\n\n    let entryStream = null\n    let entryCallback = null\n\n    const extract = this\n\n    this.on('entry', onentry)\n    this.on('error', (err) => { error = err })\n    this.on('close', onclose)\n\n    return {\n      [Symbol.asyncIterator] () {\n        return this\n      },\n      next () {\n        return new Promise(onnext)\n      },\n      return () {\n        return destroy(null)\n      },\n      throw (err) {\n        return destroy(err)\n      }\n    }\n\n    function consumeCallback (err) {\n      if (!entryCallback) return\n      const cb = entryCallback\n      entryCallback = null\n      cb(err)\n    }\n\n    function onnext (resolve, reject) {\n      if (error) {\n        return reject(error)\n      }\n\n      if (entryStream) {\n        resolve({ value: entryStream, done: false })\n        entryStream = null\n        return\n      }\n\n      promiseResolve = resolve\n      promiseReject = reject\n\n      consumeCallback(null)\n\n      if (extract._finished && promiseResolve) {\n        promiseResolve({ value: undefined, done: true })\n        promiseResolve = promiseReject = null\n      }\n    }\n\n    function onentry (header, stream, callback) {\n      entryCallback = callback\n      stream.on('error', noop) // no way around this due to tick sillyness\n\n      if (promiseResolve) {\n        promiseResolve({ value: stream, done: false })\n        promiseResolve = promiseReject = null\n      } else {\n        entryStream = stream\n      }\n    }\n\n    function onclose () {\n      consumeCallback(error)\n      if (!promiseResolve) return\n      if (error) promiseReject(error)\n      else promiseResolve({ value: undefined, done: true })\n      promiseResolve = promiseReject = null\n    }\n\n    function destroy (err) {\n      extract.destroy(err)\n      consumeCallback(err)\n      return new Promise((resolve, reject) => {\n        if (extract.destroyed) return resolve({ value: undefined, done: true })\n        extract.once('close', function () {\n          if (err) reject(err)\n          else resolve({ value: undefined, done: true })\n        })\n      })\n    }\n  }\n}\n\nmodule.exports = function extract (opts) {\n  return new Extract(opts)\n}\n\nfunction noop () {}\n\nfunction overflow (size) {\n  size &= 511\n  return size && 512 - size\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-stream/extract.js?");

/***/ }),

/***/ "./node_modules/tar-stream/headers.js":
/*!********************************************!*\
  !*** ./node_modules/tar-stream/headers.js ***!
  \********************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("const b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\n\nconst ZEROS = '0000000000000000000'\nconst SEVENS = '7777777777777777777'\nconst ZERO_OFFSET = '0'.charCodeAt(0)\nconst USTAR_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x00]) // ustar\\x00\nconst USTAR_VER = b4a.from([ZERO_OFFSET, ZERO_OFFSET])\nconst GNU_MAGIC = b4a.from([0x75, 0x73, 0x74, 0x61, 0x72, 0x20]) // ustar\\x20\nconst GNU_VER = b4a.from([0x20, 0x00])\nconst MASK = 0o7777\nconst MAGIC_OFFSET = 257\nconst VERSION_OFFSET = 263\n\nexports.decodeLongPath = function decodeLongPath (buf, encoding) {\n  return decodeStr(buf, 0, buf.length, encoding)\n}\n\nexports.encodePax = function encodePax (opts) { // TODO: encode more stuff in pax\n  let result = ''\n  if (opts.name) result += addLength(' path=' + opts.name + '\\n')\n  if (opts.linkname) result += addLength(' linkpath=' + opts.linkname + '\\n')\n  const pax = opts.pax\n  if (pax) {\n    for (const key in pax) {\n      result += addLength(' ' + key + '=' + pax[key] + '\\n')\n    }\n  }\n  return b4a.from(result)\n}\n\nexports.decodePax = function decodePax (buf) {\n  const result = {}\n\n  while (buf.length) {\n    let i = 0\n    while (i < buf.length && buf[i] !== 32) i++\n    const len = parseInt(b4a.toString(buf.subarray(0, i)), 10)\n    if (!len) return result\n\n    const b = b4a.toString(buf.subarray(i + 1, len - 1))\n    const keyIndex = b.indexOf('=')\n    if (keyIndex === -1) return result\n    result[b.slice(0, keyIndex)] = b.slice(keyIndex + 1)\n\n    buf = buf.subarray(len)\n  }\n\n  return result\n}\n\nexports.encode = function encode (opts) {\n  const buf = b4a.alloc(512)\n  let name = opts.name\n  let prefix = ''\n\n  if (opts.typeflag === 5 && name[name.length - 1] !== '/') name += '/'\n  if (b4a.byteLength(name) !== name.length) return null // utf-8\n\n  while (b4a.byteLength(name) > 100) {\n    const i = name.indexOf('/')\n    if (i === -1) return null\n    prefix += prefix ? '/' + name.slice(0, i) : name.slice(0, i)\n    name = name.slice(i + 1)\n  }\n\n  if (b4a.byteLength(name) > 100 || b4a.byteLength(prefix) > 155) return null\n  if (opts.linkname && b4a.byteLength(opts.linkname) > 100) return null\n\n  b4a.write(buf, name)\n  b4a.write(buf, encodeOct(opts.mode & MASK, 6), 100)\n  b4a.write(buf, encodeOct(opts.uid, 6), 108)\n  b4a.write(buf, encodeOct(opts.gid, 6), 116)\n  encodeSize(opts.size, buf, 124)\n  b4a.write(buf, encodeOct((opts.mtime.getTime() / 1000) | 0, 11), 136)\n\n  buf[156] = ZERO_OFFSET + toTypeflag(opts.type)\n\n  if (opts.linkname) b4a.write(buf, opts.linkname, 157)\n\n  b4a.copy(USTAR_MAGIC, buf, MAGIC_OFFSET)\n  b4a.copy(USTAR_VER, buf, VERSION_OFFSET)\n  if (opts.uname) b4a.write(buf, opts.uname, 265)\n  if (opts.gname) b4a.write(buf, opts.gname, 297)\n  b4a.write(buf, encodeOct(opts.devmajor || 0, 6), 329)\n  b4a.write(buf, encodeOct(opts.devminor || 0, 6), 337)\n\n  if (prefix) b4a.write(buf, prefix, 345)\n\n  b4a.write(buf, encodeOct(cksum(buf), 6), 148)\n\n  return buf\n}\n\nexports.decode = function decode (buf, filenameEncoding, allowUnknownFormat) {\n  let typeflag = buf[156] === 0 ? 0 : buf[156] - ZERO_OFFSET\n\n  let name = decodeStr(buf, 0, 100, filenameEncoding)\n  const mode = decodeOct(buf, 100, 8)\n  const uid = decodeOct(buf, 108, 8)\n  const gid = decodeOct(buf, 116, 8)\n  const size = decodeOct(buf, 124, 12)\n  const mtime = decodeOct(buf, 136, 12)\n  const type = toType(typeflag)\n  const linkname = buf[157] === 0 ? null : decodeStr(buf, 157, 100, filenameEncoding)\n  const uname = decodeStr(buf, 265, 32)\n  const gname = decodeStr(buf, 297, 32)\n  const devmajor = decodeOct(buf, 329, 8)\n  const devminor = decodeOct(buf, 337, 8)\n\n  const c = cksum(buf)\n\n  // checksum is still initial value if header was null.\n  if (c === 8 * 32) return null\n\n  // valid checksum\n  if (c !== decodeOct(buf, 148, 8)) throw new Error('Invalid tar header. Maybe the tar is corrupted or it needs to be gunzipped?')\n\n  if (isUSTAR(buf)) {\n    // ustar (posix) format.\n    // prepend prefix, if present.\n    if (buf[345]) name = decodeStr(buf, 345, 155, filenameEncoding) + '/' + name\n  } else if (isGNU(buf)) {\n    // 'gnu'/'oldgnu' format. Similar to ustar, but has support for incremental and\n    // multi-volume tarballs.\n  } else {\n    if (!allowUnknownFormat) {\n      throw new Error('Invalid tar header: unknown format.')\n    }\n  }\n\n  // to support old tar versions that use trailing / to indicate dirs\n  if (typeflag === 0 && name && name[name.length - 1] === '/') typeflag = 5\n\n  return {\n    name,\n    mode,\n    uid,\n    gid,\n    size,\n    mtime: new Date(1000 * mtime),\n    type,\n    linkname,\n    uname,\n    gname,\n    devmajor,\n    devminor,\n    pax: null\n  }\n}\n\nfunction isUSTAR (buf) {\n  return b4a.equals(USTAR_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6))\n}\n\nfunction isGNU (buf) {\n  return b4a.equals(GNU_MAGIC, buf.subarray(MAGIC_OFFSET, MAGIC_OFFSET + 6)) &&\n    b4a.equals(GNU_VER, buf.subarray(VERSION_OFFSET, VERSION_OFFSET + 2))\n}\n\nfunction clamp (index, len, defaultValue) {\n  if (typeof index !== 'number') return defaultValue\n  index = ~~index // Coerce to integer.\n  if (index >= len) return len\n  if (index >= 0) return index\n  index += len\n  if (index >= 0) return index\n  return 0\n}\n\nfunction toType (flag) {\n  switch (flag) {\n    case 0:\n      return 'file'\n    case 1:\n      return 'link'\n    case 2:\n      return 'symlink'\n    case 3:\n      return 'character-device'\n    case 4:\n      return 'block-device'\n    case 5:\n      return 'directory'\n    case 6:\n      return 'fifo'\n    case 7:\n      return 'contiguous-file'\n    case 72:\n      return 'pax-header'\n    case 55:\n      return 'pax-global-header'\n    case 27:\n      return 'gnu-long-link-path'\n    case 28:\n    case 30:\n      return 'gnu-long-path'\n  }\n\n  return null\n}\n\nfunction toTypeflag (flag) {\n  switch (flag) {\n    case 'file':\n      return 0\n    case 'link':\n      return 1\n    case 'symlink':\n      return 2\n    case 'character-device':\n      return 3\n    case 'block-device':\n      return 4\n    case 'directory':\n      return 5\n    case 'fifo':\n      return 6\n    case 'contiguous-file':\n      return 7\n    case 'pax-header':\n      return 72\n  }\n\n  return 0\n}\n\nfunction indexOf (block, num, offset, end) {\n  for (; offset < end; offset++) {\n    if (block[offset] === num) return offset\n  }\n  return end\n}\n\nfunction cksum (block) {\n  let sum = 8 * 32\n  for (let i = 0; i < 148; i++) sum += block[i]\n  for (let j = 156; j < 512; j++) sum += block[j]\n  return sum\n}\n\nfunction encodeOct (val, n) {\n  val = val.toString(8)\n  if (val.length > n) return SEVENS.slice(0, n) + ' '\n  return ZEROS.slice(0, n - val.length) + val + ' '\n}\n\nfunction encodeSizeBin (num, buf, off) {\n  buf[off] = 0x80\n  for (let i = 11; i > 0; i--) {\n    buf[off + i] = num & 0xff\n    num = Math.floor(num / 0x100)\n  }\n}\n\nfunction encodeSize (num, buf, off) {\n  if (num.toString(8).length > 11) {\n    encodeSizeBin(num, buf, off)\n  } else {\n    b4a.write(buf, encodeOct(num, 11), off)\n  }\n}\n\n/* Copied from the node-tar repo and modified to meet\n * tar-stream coding standard.\n *\n * Source: https://github.com/npm/node-tar/blob/51b6627a1f357d2eb433e7378e5f05e83b7aa6cd/lib/header.js#L349\n */\nfunction parse256 (buf) {\n  // first byte MUST be either 80 or FF\n  // 80 for positive, FF for 2's comp\n  let positive\n  if (buf[0] === 0x80) positive = true\n  else if (buf[0] === 0xFF) positive = false\n  else return null\n\n  // build up a base-256 tuple from the least sig to the highest\n  const tuple = []\n  let i\n  for (i = buf.length - 1; i > 0; i--) {\n    const byte = buf[i]\n    if (positive) tuple.push(byte)\n    else tuple.push(0xFF - byte)\n  }\n\n  let sum = 0\n  const l = tuple.length\n  for (i = 0; i < l; i++) {\n    sum += tuple[i] * Math.pow(256, i)\n  }\n\n  return positive ? sum : -1 * sum\n}\n\nfunction decodeOct (val, offset, length) {\n  val = val.subarray(offset, offset + length)\n  offset = 0\n\n  // If prefixed with 0x80 then parse as a base-256 integer\n  if (val[offset] & 0x80) {\n    return parse256(val)\n  } else {\n    // Older versions of tar can prefix with spaces\n    while (offset < val.length && val[offset] === 32) offset++\n    const end = clamp(indexOf(val, 32, offset, val.length), val.length, val.length)\n    while (offset < end && val[offset] === 0) offset++\n    if (end === offset) return 0\n    return parseInt(b4a.toString(val.subarray(offset, end)), 8)\n  }\n}\n\nfunction decodeStr (val, offset, length, encoding) {\n  return b4a.toString(val.subarray(offset, indexOf(val, 0, offset, offset + length)), encoding)\n}\n\nfunction addLength (str) {\n  const len = b4a.byteLength(str)\n  let digits = Math.floor(Math.log(len) / Math.log(10)) + 1\n  if (len + digits >= Math.pow(10, digits)) digits++\n\n  return (len + digits) + str\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-stream/headers.js?");

/***/ }),

/***/ "./node_modules/tar-stream/index.js":
/*!******************************************!*\
  !*** ./node_modules/tar-stream/index.js ***!
  \******************************************/
/***/ ((__unused_webpack_module, exports, __webpack_require__) => {

eval("exports.extract = __webpack_require__(/*! ./extract */ \"./node_modules/tar-stream/extract.js\")\nexports.pack = __webpack_require__(/*! ./pack */ \"./node_modules/tar-stream/pack.js\")\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-stream/index.js?");

/***/ }),

/***/ "./node_modules/tar-stream/pack.js":
/*!*****************************************!*\
  !*** ./node_modules/tar-stream/pack.js ***!
  \*****************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const { Readable, Writable, getStreamError } = __webpack_require__(/*! streamx */ \"./node_modules/streamx/index.js\")\nconst b4a = __webpack_require__(/*! b4a */ \"./node_modules/b4a/browser.js\")\n\nconst constants = __webpack_require__(/*! ./constants */ \"./node_modules/tar-stream/constants.js\")\nconst headers = __webpack_require__(/*! ./headers */ \"./node_modules/tar-stream/headers.js\")\n\nconst DMODE = 0o755\nconst FMODE = 0o644\n\nconst END_OF_TAR = b4a.alloc(1024)\n\nclass Sink extends Writable {\n  constructor (pack, header, callback) {\n    super({ mapWritable, eagerOpen: true })\n\n    this.written = 0\n    this.header = header\n\n    this._callback = callback\n    this._linkname = null\n    this._isLinkname = header.type === 'symlink' && !header.linkname\n    this._isVoid = header.type !== 'file' && header.type !== 'contiguous-file'\n    this._finished = false\n    this._pack = pack\n    this._openCallback = null\n\n    if (this._pack._stream === null) this._pack._stream = this\n    else this._pack._pending.push(this)\n  }\n\n  _open (cb) {\n    this._openCallback = cb\n    if (this._pack._stream === this) this._continueOpen()\n  }\n\n  _continuePack (err) {\n    if (this._callback === null) return\n\n    const callback = this._callback\n    this._callback = null\n\n    callback(err)\n  }\n\n  _continueOpen () {\n    if (this._pack._stream === null) this._pack._stream = this\n\n    const cb = this._openCallback\n    this._openCallback = null\n    if (cb === null) return\n\n    if (this._pack.destroying) return cb(new Error('pack stream destroyed'))\n    if (this._pack._finalized) return cb(new Error('pack stream is already finalized'))\n\n    this._pack._stream = this\n\n    if (!this._isLinkname) {\n      this._pack._encode(this.header)\n    }\n\n    if (this._isVoid) {\n      this._finish()\n      this._continuePack(null)\n    }\n\n    cb(null)\n  }\n\n  _write (data, cb) {\n    if (this._isLinkname) {\n      this._linkname = this._linkname ? b4a.concat([this._linkname, data]) : data\n      return cb(null)\n    }\n\n    if (this._isVoid) {\n      if (data.byteLength > 0) {\n        return cb(new Error('No body allowed for this entry'))\n      }\n      return cb()\n    }\n\n    this.written += data.byteLength\n    if (this._pack.push(data)) return cb()\n    this._pack._drain = cb\n  }\n\n  _finish () {\n    if (this._finished) return\n    this._finished = true\n\n    if (this._isLinkname) {\n      this.header.linkname = this._linkname ? b4a.toString(this._linkname, 'utf-8') : ''\n      this._pack._encode(this.header)\n    }\n\n    overflow(this._pack, this.header.size)\n\n    this._pack._done(this)\n  }\n\n  _final (cb) {\n    if (this.written !== this.header.size) { // corrupting tar\n      return cb(new Error('Size mismatch'))\n    }\n\n    this._finish()\n    cb(null)\n  }\n\n  _getError () {\n    return getStreamError(this) || new Error('tar entry destroyed')\n  }\n\n  _predestroy () {\n    this._pack.destroy(this._getError())\n  }\n\n  _destroy (cb) {\n    this._pack._done(this)\n\n    this._continuePack(this._finished ? null : this._getError())\n\n    cb()\n  }\n}\n\nclass Pack extends Readable {\n  constructor (opts) {\n    super(opts)\n    this._drain = noop\n    this._finalized = false\n    this._finalizing = false\n    this._pending = []\n    this._stream = null\n  }\n\n  entry (header, buffer, callback) {\n    if (this._finalized || this.destroying) throw new Error('already finalized or destroyed')\n\n    if (typeof buffer === 'function') {\n      callback = buffer\n      buffer = null\n    }\n\n    if (!callback) callback = noop\n\n    if (!header.size || header.type === 'symlink') header.size = 0\n    if (!header.type) header.type = modeToType(header.mode)\n    if (!header.mode) header.mode = header.type === 'directory' ? DMODE : FMODE\n    if (!header.uid) header.uid = 0\n    if (!header.gid) header.gid = 0\n    if (!header.mtime) header.mtime = new Date()\n\n    if (typeof buffer === 'string') buffer = b4a.from(buffer)\n\n    const sink = new Sink(this, header, callback)\n\n    if (b4a.isBuffer(buffer)) {\n      header.size = buffer.byteLength\n      sink.write(buffer)\n      sink.end()\n      return sink\n    }\n\n    if (sink._isVoid) {\n      return sink\n    }\n\n    return sink\n  }\n\n  finalize () {\n    if (this._stream || this._pending.length > 0) {\n      this._finalizing = true\n      return\n    }\n\n    if (this._finalized) return\n    this._finalized = true\n\n    this.push(END_OF_TAR)\n    this.push(null)\n  }\n\n  _done (stream) {\n    if (stream !== this._stream) return\n\n    this._stream = null\n\n    if (this._finalizing) this.finalize()\n    if (this._pending.length) this._pending.shift()._continueOpen()\n  }\n\n  _encode (header) {\n    if (!header.pax) {\n      const buf = headers.encode(header)\n      if (buf) {\n        this.push(buf)\n        return\n      }\n    }\n    this._encodePax(header)\n  }\n\n  _encodePax (header) {\n    const paxHeader = headers.encodePax({\n      name: header.name,\n      linkname: header.linkname,\n      pax: header.pax\n    })\n\n    const newHeader = {\n      name: 'PaxHeader',\n      mode: header.mode,\n      uid: header.uid,\n      gid: header.gid,\n      size: paxHeader.byteLength,\n      mtime: header.mtime,\n      type: 'pax-header',\n      linkname: header.linkname && 'PaxHeader',\n      uname: header.uname,\n      gname: header.gname,\n      devmajor: header.devmajor,\n      devminor: header.devminor\n    }\n\n    this.push(headers.encode(newHeader))\n    this.push(paxHeader)\n    overflow(this, paxHeader.byteLength)\n\n    newHeader.size = header.size\n    newHeader.type = header.type\n    this.push(headers.encode(newHeader))\n  }\n\n  _doDrain () {\n    const drain = this._drain\n    this._drain = noop\n    drain()\n  }\n\n  _predestroy () {\n    const err = getStreamError(this)\n\n    if (this._stream) this._stream.destroy(err)\n\n    while (this._pending.length) {\n      const stream = this._pending.shift()\n      stream.destroy(err)\n      stream._continueOpen()\n    }\n\n    this._doDrain()\n  }\n\n  _read (cb) {\n    this._doDrain()\n    cb()\n  }\n}\n\nmodule.exports = function pack (opts) {\n  return new Pack(opts)\n}\n\nfunction modeToType (mode) {\n  switch (mode & constants.S_IFMT) {\n    case constants.S_IFBLK: return 'block-device'\n    case constants.S_IFCHR: return 'character-device'\n    case constants.S_IFDIR: return 'directory'\n    case constants.S_IFIFO: return 'fifo'\n    case constants.S_IFLNK: return 'symlink'\n  }\n\n  return 'file'\n}\n\nfunction noop () {}\n\nfunction overflow (self, size) {\n  size &= 511\n  if (size) self.push(END_OF_TAR.subarray(0, 512 - size))\n}\n\nfunction mapWritable (buf) {\n  return b4a.isBuffer(buf) ? buf : b4a.from(buf)\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/tar-stream/pack.js?");

/***/ }),

/***/ "./node_modules/text-decoder/index.js":
/*!********************************************!*\
  !*** ./node_modules/text-decoder/index.js ***!
  \********************************************/
/***/ ((module, __unused_webpack_exports, __webpack_require__) => {

eval("const PassThroughDecoder = __webpack_require__(/*! ./lib/pass-through-decoder */ \"./node_modules/text-decoder/lib/browser-decoder.js\")\nconst UTF8Decoder = __webpack_require__(/*! ./lib/utf8-decoder */ \"./node_modules/text-decoder/lib/browser-decoder.js\")\n\nmodule.exports = class TextDecoder {\n  constructor (encoding = 'utf8') {\n    this.encoding = normalizeEncoding(encoding)\n\n    switch (this.encoding) {\n      case 'utf8':\n        this.decoder = new UTF8Decoder()\n        break\n      case 'utf16le':\n      case 'base64':\n        throw new Error('Unsupported encoding: ' + this.encoding)\n      default:\n        this.decoder = new PassThroughDecoder(this.encoding)\n    }\n  }\n\n  get remaining () {\n    return this.decoder.remaining\n  }\n\n  push (data) {\n    if (typeof data === 'string') return data\n    return this.decoder.decode(data)\n  }\n\n  // For Node.js compatibility\n  write (data) {\n    return this.push(data)\n  }\n\n  end (data) {\n    let result = ''\n    if (data) result = this.push(data)\n    result += this.decoder.flush()\n    return result\n  }\n}\n\nfunction normalizeEncoding (encoding) {\n  encoding = encoding.toLowerCase()\n\n  switch (encoding) {\n    case 'utf8':\n    case 'utf-8':\n      return 'utf8'\n    case 'ucs2':\n    case 'ucs-2':\n    case 'utf16le':\n    case 'utf-16le':\n      return 'utf16le'\n    case 'latin1':\n    case 'binary':\n      return 'latin1'\n    case 'base64':\n    case 'ascii':\n    case 'hex':\n      return encoding\n    default:\n      throw new Error('Unknown encoding: ' + encoding)\n  }\n};\n\n\n//# sourceURL=webpack://consentbit/./node_modules/text-decoder/index.js?");

/***/ }),

/***/ "./node_modules/text-decoder/lib/browser-decoder.js":
/*!**********************************************************!*\
  !*** ./node_modules/text-decoder/lib/browser-decoder.js ***!
  \**********************************************************/
/***/ ((module) => {

eval("module.exports = class BrowserDecoder {\n  constructor (encoding) {\n    this.decoder = new TextDecoder(encoding === 'utf16le' ? 'utf16-le' : encoding)\n  }\n\n  get remaining () {\n    return -1\n  }\n\n  decode (data) {\n    return this.decoder.decode(data, { stream: true })\n  }\n\n  flush () {\n    return this.decoder.decode(new Uint8Array(0))\n  }\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/text-decoder/lib/browser-decoder.js?");

/***/ }),

/***/ "./node_modules/wrappy/wrappy.js":
/*!***************************************!*\
  !*** ./node_modules/wrappy/wrappy.js ***!
  \***************************************/
/***/ ((module) => {

eval("// Returns a wrapper function that returns a wrapped callback\n// The wrapper function should do some stuff, and return a\n// presumably different callback function.\n// This makes sure that own properties are retained, so that\n// decorations and such are not lost along the way.\nmodule.exports = wrappy\nfunction wrappy (fn, cb) {\n  if (fn && cb) return wrappy(fn)(cb)\n\n  if (typeof fn !== 'function')\n    throw new TypeError('need wrapper function')\n\n  Object.keys(fn).forEach(function (k) {\n    wrapper[k] = fn[k]\n  })\n\n  return wrapper\n\n  function wrapper() {\n    var args = new Array(arguments.length)\n    for (var i = 0; i < args.length; i++) {\n      args[i] = arguments[i]\n    }\n    var ret = fn.apply(this, args)\n    var cb = args[args.length-1]\n    if (typeof ret === 'function' && ret !== cb) {\n      Object.keys(cb).forEach(function (k) {\n        ret[k] = cb[k]\n      })\n    }\n    return ret\n  }\n}\n\n\n//# sourceURL=webpack://consentbit/./node_modules/wrappy/wrappy.js?");

/***/ })

}]);